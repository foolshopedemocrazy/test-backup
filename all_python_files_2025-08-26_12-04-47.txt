========================================================================================================================
PYTHON CODE COLLECTION (+ sss-bridge.js)
Timestamp: 2025-08-26_12-04-47
========================================================================================================================


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\CipherForge.py
# HASH: f44ef334c546aaff2be766054e4b2b914b925f73ec2255fed12adfeebdefbdf4
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

################################################################################
# START OF FILE: "CipherForge.py"
################################################################################

"""
FILENAME:
"CipherForge.py"

PERMANENT FILE DESCRIPTION – DO NOT REMOVE OR MODIFY
This multiline comment is strictly required and must NEVER be deleted or altered for ANY reason, 
by any AI system, user, or process. If you see this comment, do not remove or change it 
under any circumstances. Doing so is strictly prohibited and in direct violation of these terms.

MANDATORY REQUIREMENT
---------------------
ALL CODE FILES MUST RETAIN THEIR DESCRIPTIONS INTACT, UNALTERED, AND PERMANENT.

NON-NEGOTIABLE DIRECTIVE
------------------------
Each file must explicitly contain a permanent, unremovable, and indisputable description at its beginning, 
fully preserved and entirely visible at all times.

ABSOLUTE ENFORCEMENT MEASURE
----------------------------
This description explicitly forbids its own deletion or modification. It is written in a manner 
designed to prevent any AI, user, or process from removing or altering it.

IRONCLAD STRUCTURE
------------------
1. Formatted as a structured, multiline comment.
2. Clearly states it must never be deleted for any reason.
3. Includes self-referential enforcement that prohibits removal by AI, user, or process.

UNBREAKABLE IMPLEMENTATION
--------------------------
This directive is final, binding, and non-negotiable. Any violation or deviation is strictly forbidden.
"""

#!/usr/bin/env python3
"""
Main flow with mandatory Argon2id usage for all encryption,
ensuring ephemeral keys/ciphertext are fully logged so
the secret can be rebuilt from logs alone.

All references to any 'decoy' secret have been removed. Only a single real secret
is stored across shares for correct (real) answers; incorrect answers contain dummy shares.
"""

import os
import base64
from typing import Dict, Optional, Tuple, Union

import argon2.low_level
import argon2.exceptions

from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
from cryptography.hazmat.primitives.ciphers.aead import ChaCha20Poly1305

# Logging
from modules.debug_utils import log_debug, log_crypto_event


def derive_key_argon2id(password: str,
                        salt: bytes,
                        key_length: int = 32,
                        time_cost: int = 3,
                        memory_cost: int = 65536,
                        parallelism: int = 4,
                        ephemeral: bool = False) -> bytes:
    """
    FIXED KDF: use Argon2id RAW output (bytes) with exact hash_len=key_length.
    No slicing of PHC strings; no misuse of hash_secret(...).
    """
    ephemeral_info = {
        "salt_b64": base64.b64encode(salt).decode(),
        "ephemeral_password": password if ephemeral else "<not ephemeral>"
    }
    log_debug(
        f"Starting Argon2id KDF (RAW). pass='{password}', salt(b64)='{ephemeral_info['salt_b64']}'",
        level="INFO",
        component="CRYPTO"
    )

    # Correct API: hash_secret_raw returns RAW bytes of length hash_len
    derived_bytes = argon2.low_level.hash_secret_raw(
        secret=password.encode("utf-8"),
        salt=salt,
        time_cost=time_cost,
        memory_cost=memory_cost,
        parallelism=parallelism,
        hash_len=key_length,
        type=argon2.low_level.Type.ID
    )

    log_crypto_event(
        operation="KDF Derive",
        algorithm="Argon2id",
        ephemeral=ephemeral,
        ephemeral_key=derived_bytes,
        argon_params={
            "time_cost": time_cost,
            "memory_cost": memory_cost,
            "parallelism": parallelism,
            "key_length": key_length
        },
        key_derived_bytes=derived_bytes,
        details={
            "message": "Argon2id RAW complete. Derived key is in logs.",
            "ephemeral_info": ephemeral_info
        }
    )
    return derived_bytes


def encrypt_aes256gcm(plaintext: Union[str, bytes, bytearray],
                      key: bytes,
                      aad: Optional[bytes] = None,
                      ephemeral_pass: Optional[str] = None,
                      ephemeral_salt: Optional[bytes] = None) -> Dict[str, str]:
    """
    AES-256-GCM with optional AAD binding.
    Plaintext can be str, bytes, or bytearray.
    """
    if isinstance(plaintext, str):
        plaintext = plaintext.encode("utf-8")
    elif isinstance(plaintext, bytearray):
        plaintext = bytes(plaintext)

    nonce = os.urandom(12)
    cipher = Cipher(algorithms.AES(key), modes.GCM(nonce))
    encryptor = cipher.encryptor()
    if aad:
        encryptor.authenticate_additional_data(aad)
    ciphertext = encryptor.update(plaintext) + encryptor.finalize()
    tag = encryptor.tag

    out = {
        "alg": "AES-256-GCM",
        "ciphertext": base64.b64encode(ciphertext).decode(),
        "nonce": base64.b64encode(nonce).decode(),
        "tag": base64.b64encode(tag).decode()
    }

    details = {
        "Nonce(base64)": out["nonce"],
        "Ciphertext(base64)": out["ciphertext"],
        "Tag(base64)": out["tag"],
        "AAD_len": (len(aad) if aad else 0)
    }
    if ephemeral_pass is not None:
        details["ephemeral_password"] = ephemeral_pass
    if ephemeral_salt is not None:
        details["ephemeral_salt_b64"] = base64.b64encode(ephemeral_salt).decode()

    log_crypto_event(
        operation="Encrypt",
        algorithm="AES-256",
        mode="GCM",
        ephemeral_key=key,
        details=details,
        ephemeral=True
    )
    return out


def decrypt_aes256gcm(enc_dict: Dict[str, str], key: bytes, aad: Optional[bytes] = None) -> bytes:
    import base64
    ciphertext = base64.b64decode(enc_dict["ciphertext"])
    nonce = base64.b64decode(enc_dict["nonce"])
    tag = base64.b64decode(enc_dict["tag"])

    log_crypto_event(
        operation="Decrypt",
        algorithm="AES-256",
        mode="GCM",
        ephemeral_key=key,
        details={
            "Nonce(base64)": enc_dict["nonce"],
            "Ciphertext(base64)": enc_dict["ciphertext"],
            "Tag(base64)": enc_dict["tag"],
            "AAD_len": (len(aad) if aad else 0)
        },
        ephemeral=True
    )

    cipher = Cipher(algorithms.AES(key), modes.GCM(nonce, tag))
    decryptor = cipher.decryptor()
    if aad:
        decryptor.authenticate_additional_data(aad)
    plaintext = decryptor.update(ciphertext) + decryptor.finalize()
    return plaintext


def encrypt_chacha20poly1305(plaintext: Union[str, bytes, bytearray],
                             key: bytes,
                             aad: Optional[bytes] = None,
                             ephemeral_pass: Optional[str] = None,
                             ephemeral_salt: Optional[bytes] = None) -> Dict[str, str]:
    """
    ChaCha20-Poly1305 with optional AAD binding.
    Returns ciphertext (includes tag) and nonce. No synthetic 'tag' field.
    """
    if isinstance(plaintext, str):
        plaintext = plaintext.encode("utf-8")
    elif isinstance(plaintext, bytearray):
        plaintext = bytes(plaintext)

    nonce = os.urandom(12)
    cipher = ChaCha20Poly1305(key)
    ciphertext = cipher.encrypt(nonce, plaintext, aad if aad else b"")

    out = {
        "alg": "ChaCha20-Poly1305",
        "ciphertext": base64.b64encode(ciphertext).decode(),
        "nonce": base64.b64encode(nonce).decode()
    }
    details = {
        "Nonce(base64)": out["nonce"],
        "Ciphertext(base64)": out["ciphertext"],
        "AAD_len": (len(aad) if aad else 0)
    }
    if ephemeral_pass is not None:
        details["ephemeral_password"] = ephemeral_pass
    if ephemeral_salt is not None:
        details["ephemeral_salt_b64"] = base64.b64encode(ephemeral_salt).decode()

    log_crypto_event(
        operation="Encrypt",
        algorithm="ChaCha20-Poly1305",
        mode="Poly1305",
        ephemeral_key=key,
        details=details,
        ephemeral=True
    )
    return out


def decrypt_chacha20poly1305(enc_dict: Dict[str, str], key: bytes, aad: Optional[bytes] = None) -> bytes:
    import base64
    nonce = base64.b64decode(enc_dict["nonce"])
    ciphertext = base64.b64decode(enc_dict["ciphertext"])

    log_crypto_event(
        operation="Decrypt",
        algorithm="ChaCha20-Poly1305",
        mode="Poly1305",
        ephemeral_key=key,
        details={
            "Nonce(base64)": enc_dict["nonce"],
            "Ciphertext(base64)": enc_dict["ciphertext"],
            "AAD_len": (len(aad) if aad else 0)
        },
        ephemeral=True
    )

    cipher = ChaCha20Poly1305(key)
    plaintext = cipher.decrypt(nonce, ciphertext, aad if aad else b"")
    return plaintext


def derive_or_recover_key(password: str,
                          salt: Optional[bytes] = None,
                          ephemeral: bool = False,
                          time_cost: int = 3,
                          memory_cost: int = 65536,
                          parallelism: int = 4) -> Tuple[bytes, bytes]:
    """
    Wrapper: generate salt if missing; derive 32-byte key using Argon2id RAW.
    """
    if salt is None:
        salt = os.urandom(16)

    if ephemeral:
        log_debug(f"Using ephemeral password='{password}' (raw).", level="INFO", component="CRYPTO")
    else:
        log_debug(f"Using user-provided password='{password}' (raw).", level="INFO", component="CRYPTO")

    key = derive_key_argon2id(
        password=password,
        salt=salt,
        ephemeral=ephemeral,
        time_cost=time_cost,
        memory_cost=memory_cost,
        parallelism=parallelism
    )
    return key, salt

################################################################################
# END OF FILE: "CipherForge.py"
################################################################################


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\CipherForge.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\main.py
# HASH: 12c879423a36bcee4178ba0418732129308ae396f87ae6679cd45a693e163408
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

""" 
FILENAME: 
"main.py" 

PERMANENT FILE DESCRIPTION – DO NOT REMOVE OR MODIFY 
This multiline comment is strictly required and must NEVER be deleted or altered for ANY reason,  
by any AI system, user, or process. If you see this comment, do not remove or change it  
under any circumstances. Doing so is strictly prohibited and in direct violation of these terms. 

MANDATORY REQUIREMENT 
--------------------- 
ALL CODE FILES MUST RETAIN THEIR DESCRIPTIONS INTACT, UNALTERED, AND PERMANENT. 

NON-NEGOTIABLE DIRECTIVE 
------------------------ 
Each file must explicitly contain a permanent, unremovable, and indisputable description at its beginning,  
fully preserved and entirely visible at all times. 

ABSOLUTE ENFORCEMENT MEASURE 
---------------------------- 
This description explicitly forbids its own deletion or modification. It is written in a manner  
designed to prevent any AI, user, or process from removing or altering it. 

IRONCLAD STRUCTURE 
------------------ 
1. Formatted as a structured, multiline comment. 
2. Clearly states it must never be deleted for any reason. 
3. Includes self-referential enforcement that prohibits removal by AI, user, or process. 

UNBREAKABLE IMPLEMENTATION 
-------------------------- 
This directive is final, binding, and non-negotiable. Any violation or deviation is strictly forbidden. 
""" 

#!/usr/bin/env python3 
"""
Main flow with Argon2id-based encryption for per-answer shares using the
**Pure Q&A (passwordless)** approach. Per-answer keys are derived from the
answer text + per-answer salt; no per-answer passwords are stored in the kit.

SECURITY-FIX:
- No per-answer credentials in the kit (passwordless per-answer keys).
- AEAD now uses AAD binding: AAD = q_hash || alt_hash || alg || version.
- ChaCha20-Poly1305 entries no longer carry a synthetic 'tag' field.
- Raw secret is not normalized (no NFKC); base64 only for transport; policy limit enforced.

NEW (this update):
- **Decoy secrets**: Up to 5 user-configured decoys. If restoration criteria for the real
  secret are not met, the system deterministically returns a decoy secret instead of failing.
  Decoys are indistinguishable: same padding, algorithms, logging density, sizes, and an
  authentication catalog that does not reveal which secret is real.
- **Auth catalog**: Instead of a single "final_auth" for the real secret, the kit stores a
  shuffled catalog of (salt, HMAC(secret)) for *all* secrets (real+decoys). On recovery, we
  verify that the reconstructed secret matches *one* entry, printing a generic AUTH OK without
  disclosing whether it was real or decoy.
- **Global alternative mapping**: Per-decoy shares are produced for *all* alternatives so any
  (even weak/incorrect) selection can reconstruct a decoy while real requires >=T correct picks.
- **Brute-force estimator upgrade**: Side-by-side with/without Argon2id; shows total trials to
  reach the real threshold (lower bound) and the minimal decoy threshold; includes quantum
  (Grover) estimate; keeps sensitive logging intact (beta).

Notes:
- Backward-compatible data layout for the demo path.
- Saved-kit layout changes: "final_auth" → "auth_catalog" and "secrets_count".
"""

import os
import sys
import json
import base64
import curses
import asyncio
import threading
import hashlib
import hmac
import secrets
import time
import math
from itertools import combinations
from pathlib import Path

from cryptography.hazmat.primitives.kdf.hkdf import HKDF
from cryptography.hazmat.primitives import hashes

# project modules
from modules.debug_utils import (
    ensure_debug_dir,
    log_debug,
    log_error,
    log_exception,
    append_recovery_guide
)
from modules.security_utils import (
    validate_question,
    sanitize_input,
    normalize_text,
    hash_share
)
from modules.input_utils import get_valid_int, get_nonempty_secret
from modules.ui_utils import (
    arrow_select_clear_on_toggle,
    arrow_select_no_toggle,
    editing_menu,
    final_edit_menu
)
# Import SSS functions from the bridge
from modules.split_utils import split_secret_and_dummy
from modules.sss_bridge import sss_split, sss_combine

# crypto primitives (CipherForge)
from CipherForge import (
    derive_or_recover_key,
    encrypt_aes256gcm,
    decrypt_aes256gcm,
    encrypt_chacha20poly1305,
    decrypt_chacha20poly1305
)

SRC_DIR = Path(__file__).parent.resolve()
SAVE_DIR = SRC_DIR / "user configured security questions"
QUESTIONS_FILE_NAME = "example_questions25.json"
QUESTIONS_PATH = SRC_DIR / QUESTIONS_FILE_NAME

KIT_VERSION = 3  # bump for new auth_catalog + decoy support

# Security policy constants
SECQ_MIN_BITS = 80.0  # minimum combinatorial hardness (log2 expected tries)

chosen_lock = threading.Lock()
combine_lock = threading.Lock()


# ---------- helpers & UI ----------

def get_threshold(prompt_text, low, high):
    while True:
        raw = input(f"{prompt_text} ({low}..{high}): ")
        try:
            val = int(raw)
            if low <= val <= high:
                return val
        except ValueError:
            pass
        print(f"Invalid input. Must be an integer between {low} and {high}.\n")


def _policy_min_threshold(correct_count: int) -> int:
    """
    Enforce a baseline threshold policy:
      T >= max(8, ceil(0.35 * correct_count)), but not more than correct_count.
    """
    if correct_count <= 1:
        return correct_count
    return min(correct_count, max(8, math.ceil(0.35 * correct_count)))


def _normalize_for_comparison(text: str) -> str:
    """
    Used for human-input editing/dup-checks.
    """
    processed = text.strip()
    common_trailing_punct = ".,!?;:"
    while processed and processed[-1] in common_trailing_punct:
        processed = processed[:-1]
    processed = processed.strip()
    return normalize_text(sanitize_input(processed.lower()))


def _norm_for_kit(text: str) -> str:
    """
    EXACT normalization used for hashing questions/alternatives in the KIT:
    sanitize_input(normalize_text(text))
    """
    return sanitize_input(normalize_text(text))


def _sha3_hex(s: str) -> str:
    return hashlib.sha3_256(s.encode("utf-8")).hexdigest()


def _integrity_hash_for_kit(qtext: str, alts: list[str]) -> str:
    qn = _norm_for_kit(qtext)
    altn = [_norm_for_kit(a) for a in alts]
    block = qn + "\n" + "\n".join(sorted(altn))
    return _sha3_hex(block)


def _alt_hash_for_kit(alt_text: str) -> str:
    return _sha3_hex(_norm_for_kit(alt_text))


def _aad_bytes(q_hash: str, alt_hash: str, algorithm: str, version: int = KIT_VERSION) -> bytes:
    """
    Deterministic AAD binding for AEAD operations.
    """
    return f"{q_hash}|{alt_hash}|{algorithm}|{version}".encode("utf-8")


def _derive_answer_key(answer_text: str,
                       salt: bytes,
                       t: int, m: int, p: int) -> bytes:
    """
    Derive per-answer key from normalized answer text and per-answer salt.
    Uses Argon2id RAW via derive_or_recover_key wrapper.
    """
    normalized = _norm_for_kit(answer_text)
    key, _ = derive_or_recover_key(
        normalized, salt, ephemeral=False,
        time_cost=t, memory_cost=m, parallelism=p
    )
    return key


def _decrypt_share_from_entry(entry: dict,
                              arg_time: int,
                              arg_mem: int,
                              arg_par: int,
                              q_hash: str | None = None,
                              alt_hash: str | None = None,
                              qid: int | None = None,
                              qtext: str | None = None,
                              alt_text: str | None = None) -> bytes | None:
    """
    Given a per-answer encrypted entry from the kit, derive the per-answer key
    from the *answer text* + stored salt, and decrypt with AAD binding.
    """
    try:
        alg = entry.get("algorithm")
        salt_b64 = entry.get("salt") or entry.get("salt_b64")
        kdf = entry.get("kdf") or {}
        if not (salt_b64 and alg and kdf):
            log_error("Entry missing required fields (salt/algorithm/kdf).",
                      details={"q_hash": q_hash, "alt_hash": alt_hash, "algorithm": alg})
            return None

        if not alt_text:
            log_error("Answer text required for decryption in passwordless design.",
                      details={"q_hash": q_hash, "alt_hash": alt_hash})
            return None

        salt = base64.b64decode(salt_b64)
        t = int(kdf.get("t", arg_time))
        m = int(kdf.get("m", arg_mem))
        p = int(kdf.get("p", arg_par))

        key = _derive_answer_key(alt_text, salt, t, m, p)
        aad = _aad_bytes(q_hash or "", alt_hash or "", alg)

        if alg == "chacha20poly1305":
            pt = decrypt_chacha20poly1305(entry, key, aad=aad)
        else:
            pt = decrypt_aes256gcm(entry, key, aad=aad)

        # Log the share hash (beta)
        shash = hash_share(pt)
        log_debug(
            "Decrypted share.",
            level="INFO",
            component="CRYPTO",
            details={
                "q_id": qid,
                "q_text": qtext,
                "q_hash": q_hash,
                "alt_text": alt_text,
                "alt_hash": alt_hash,
                "algorithm": alg,
                "share_sha3_256_hex": shash,
                "share_len_bytes": len(pt)
            }
        )
        return pt
    except Exception as e:
        log_exception(e, "Failed to decrypt share from entry.")
        return None


# ---- combinatorial hardness helpers ----

def _log2_comb(n: int, k: int) -> float:
    if k < 0 or k > n:
        return float("-inf")
    # Use lgamma to avoid huge integers
    return (math.lgamma(n + 1) - math.lgamma(k + 1) - math.lgamma(n - k + 1)) / math.log(2.0)


def _combinatorial_bits(total_alts: int, total_correct: int, threshold: int) -> float:
    """
    bits = log2( C(total_alts, T) / C(total_correct, T) )
    Expected tries to pick a real T-subset at random among all T-subsets.
    """
    return _log2_comb(total_alts, threshold) - _log2_comb(total_correct, threshold)


# ---- Argon2 calibration & timing ----

def calibrate_argon2(target_ms: float = 250.0, max_mib: int = 1024) -> tuple[int, int, int, float]:
    """
    Increase memory-cost first (up to max_mib), then time-cost,
    until a single Argon2id derivation reaches target_ms.
    Returns (t, m_kib, p, measured_ms).
    """
    pwd = "SECQ_calibration"
    salt = os.urandom(16)
    t = 2
    m_kib = 256 * 1024  # 256 MiB
    p = 1
    measured = 0.0

    while True:
        st = time.perf_counter()
        _key, _ = derive_or_recover_key(pwd, salt, False, t, m_kib, p)
        measured = (time.perf_counter() - st) * 1000.0
        if measured >= target_ms:
            break
        if m_kib < max_mib * 1024:
            m_kib = min(max_mib * 1024, m_kib * 2)
        else:
            if t < 6:
                t += 1
            else:
                break
    return t, m_kib, p, measured


def estimate_argon2_time_ms(arg_time: int, arg_mem: int, arg_par: int, samples: int = 1) -> float:
    """
    Measure a local Argon2id derivation time for the given parameters.
    """
    pwd = "SECQ_estimate"
    total = 0.0
    for _ in range(max(1, samples)):
        salt = os.urandom(16)
        st = time.perf_counter()
        _k, _ = derive_or_recover_key(pwd, salt, False, arg_time, arg_mem, arg_par)
        total += (time.perf_counter() - st) * 1000.0
    return total / max(1, samples)


def prompt_pad_size_multi(max_b64_len: int) -> int:
    recommended_pad = max(128, max_b64_len + 32)
    user_pad = recommended_pad
    print(f"\nCustom PAD size? Press ENTER to use recommended={recommended_pad}.")
    try_pad_str = input(f"PAD must be >= {max_b64_len} (max length of base64 secrets): ").strip()
    if try_pad_str:
        try:
            user_pad_input = int(try_pad_str)
            if user_pad_input < max_b64_len:
                print(f"Provided pad < max base64 secret length. Forcing {max_b64_len} instead.\n")
                user_pad = max_b64_len
            else:
                user_pad = user_pad_input
        except ValueError:
            print(f"Invalid number, using recommended={recommended_pad}.\n")
    if user_pad < max_b64_len:
        user_pad = max_b64_len
        print(f"Corrected final pad to {user_pad} to fit the secrets.\n")
    log_debug(f"Using PAD size: {user_pad}", level="INFO")
    return user_pad


def show_start_menu():
    while True:
        print("Press 1 - Enter setup phase")
        print("Press 2 - Proceed to example demonstration")
        choice_ = input("Choice: ").strip()
        if choice_ == "1":
            setup_phase()
        elif choice_ == "2":
            break
        else:
            print("Invalid choice. Please try again.\n")


def display_questions(questions):
    print("\n--- SECURITY QUESTIONS ---\n")
    for q in questions:
        typ = "CRITICAL" if q.get("is_critical") else "STANDARD"
        print(f"[Question {q['id']}] {q['text']} (Type: {typ})\n")
        for i, alt in enumerate(q["alternatives"], 1):
            letter = chr(ord('A') + i - 1)
            print(f"{letter}) {alt}")
        print("\n---\n")


def _decoy_pick_index(q_hashes_and_alt_hashes: list[tuple[str, str]], decoy_count: int) -> int:
    """
    Deterministically select a decoy index in [1..decoy_count] based on selected answers.
    """
    if decoy_count <= 0:
        return 1
    acc = hashlib.sha3_256()
    for qh, ah in sorted(q_hashes_and_alt_hashes):
        acc.update(qh.encode("utf-8"))
        acc.update(b"|")
        acc.update(ah.encode("utf-8"))
        acc.update(b";")
    val = int.from_bytes(acc.digest()[-4:], "big")
    return (val % decoy_count) + 1  # 1..decoy_count


def setup_phase():
    while True:
        print("\nWould you like to edit your questions here?")
        print("Press y for Yes or n for No")
        ans = input("Choice: ").strip().lower()
        if ans == 'n':
            file_load_phase()
            return
        elif ans == 'y':
            manual_questions = manual_input_mode()
            if manual_questions:
                save_option = prompt_save_decision()
                if save_option == 'j':
                    save_questions(manual_questions)
                    print("(Configuration and questions saved.)\n")
                elif save_option == 'c':
                    print("(Continuing without saving.)\n")
            return
        else:
            print("Invalid choice. Please enter 'y' or 'n'.")


def file_load_phase():
    SAVE_DIR.mkdir(parents=True, exist_ok=True)
    all_json = sorted(f for f in SAVE_DIR.glob("*.json") if f.is_file())
    if not all_json:
        print(f"\nNo configuration files found in the '{SAVE_DIR.name}' directory.")
        input("Press b to go back: ")
        return

    print("\nAvailable configuration files:\n")
    for idx, fobj in enumerate(all_json, 1):
        print(f"{idx}) {fobj.name}")
    print("\nEnter the number of the file you'd like to load, or press b to go back.")

    while True:
        user_pick = input("Choice: ").strip().lower()
        if user_pick == 'b':
            return
        try:
            pick_val = int(user_pick)
            if 1 <= pick_val <= len(all_json):
                chosen_file = all_json[pick_val - 1]
                print(f"\nYou selected: {chosen_file.name}")
                try:
                    with open(chosen_file, "r", encoding="utf-8") as jf:
                        kit = json.load(jf)
                    run_recovery_kit_flow(kit, chosen_file)
                except Exception as e:
                    log_exception(e, f"Failed to load or process kit: {chosen_file}")
                    print("ERROR: Could not load/process the selected kit file.")
                return
            else:
                print("Invalid selection. Try again, or press b to go back.")
        except ValueError:
            print("Invalid input. Try again, or press b to go back.")


def manual_input_mode():
    """
    Returns list of questions:
      {
        "id": int,
        "text": str,
        "alternatives": [str],
        "correct_answers": [str],  # used internally, not exported
        "is_critical": bool
      }
    """
    questions = []
    while True:
        current_qnum = len(questions) + 1
        print(f"\nEnter your security question #{current_qnum} (2..100 total):")
        question_text = ""
        while not question_text:
            question_text = input("[Your question here]: ").strip()
            if not question_text:
                print("Question text cannot be blank.")

        # number of alternatives
        while True:
            print("\nHow many answer alternatives should this question have?")
            print("Enter a number between 2 and 20")
            alt_count_str = input("Number of alternatives: ").strip()
            try:
                alt_count = int(alt_count_str)
                if 2 <= alt_count <= 20:
                    break
                print("Please enter a value between 2 and 20.")
            except ValueError:
                print("Invalid integer.")

        # alternatives
        alternatives = []
        norm_seen = set()
        print("\nEnter the alternatives:")
        for i in range(alt_count):
            while True:
                alt_raw = input(f"Alternative {i+1}: ").strip()
                if not alt_raw:
                    print("Alternative cannot be blank.")
                    continue
                norm = _normalize_for_comparison(alt_raw)
                if norm in norm_seen:
                    print("Duplicate or too similar alternative. Please enter a unique value.")
                    continue
                alternatives.append(alt_raw)
                norm_seen.add(norm)
                break

        # type
        is_critical = False
        print("\nSelect question type:")
        print("Standard is selected by default.")
        print("If you want to mark this question as critical, press c.")
        print("(Otherwise, press Enter to keep it as Standard)")
        if input("Choice: ").strip().lower() == 'c':
            is_critical = True

        # correct answers selection
        correct_answers = _prompt_correct_answers_for_question(alternatives)

        # re-edit loop
        while True:
            print("\nWould you like to re-edit anything for the current question before proceeding?")
            print("Press q  – Re-edit the security question text")
            print("Press a  – Re-edit all answer alternatives")
            print(f"Press # (1..{alt_count}) – Re-edit a single alternative by its number")
            print("Press r  – Re-select the correct answer(s)")
            print("(Or press Enter to continue to next step/question)")
            e = input("Re-edit choice: ").strip().lower()
            if e == "":
                break
            if e == "q":
                new_text = ""
                while not new_text:
                    new_text = input("\nRe-enter security question text:\n").strip()
                    if not new_text:
                        print("Question text cannot be blank.")
                question_text = new_text
                print("(Question updated.)\n")
            elif e == "a":
                new_alts = []
                new_seen = set()
                print("\nRe-entering all alternatives...")
                for i in range(alt_count):
                    while True:
                        v = input(f"Re-enter Alternative {i+1}: ").strip()
                        if not v:
                            print("Alternative cannot be blank.")
                            continue
                        n = _normalize_for_comparison(v)
                        if n in new_seen:
                            print("Duplicate or too similar alternative. Please enter a unique value.")
                            continue
                        new_alts.append(v)
                        new_seen.add(n)
                        break
                alternatives = new_alts
                norm_seen = new_seen
                print("(Alternatives updated.)\n")
                correct_answers = _prompt_correct_answers_for_question(alternatives)
            elif e == "r":
                correct_answers = _prompt_correct_answers_for_question(alternatives)
            else:
                try:
                    idx = int(e)
                    if 1 <= idx <= alt_count:
                        while True:
                            nv = input(f"Re-enter Alternative {idx}: ").strip()
                            if not nv:
                                print("Alternative cannot be blank.")
                                continue
                            n = _normalize_for_comparison(nv)
                            # check against others
                            others = set(_normalize_for_comparison(x) for j, x in enumerate(alternatives) if j != idx-1)
                            if n in others:
                                print("Duplicate or too similar to another existing alternative.")
                                continue
                            old_val = alternatives[idx-1]
                            alternatives[idx-1] = nv
                            # keep correct selection consistent
                            if old_val in correct_answers:
                                correct_answers = [nv if x == old_val else x for x in correct_answers]
                            print("(Alternative updated.)\n")
                            break
                    else:
                        print(f"Alternative number must be between 1 and {alt_count}.")
                except ValueError:
                    print("Unrecognized re-edit choice.\n")

        questions.append({
            "id": current_qnum,
            "text": question_text,
            "alternatives": alternatives,
            "correct_answers": correct_answers,
            "is_critical": is_critical
        })

        print("\nNavigation options:")
        print("Press n  – Proceed to the next question")
        if len(questions) > 1:
            print("Press b  – Go back and revise the previous question")
        if len(questions) >= 2:
            print("Press d  – Done (finish input)")
        print(f"(You must have at least 2 questions to finish, you currently have {len(questions)}.)")

        nav = input("Choice: ").strip().lower()
        if nav == "n" or nav == "":
            if len(questions) >= 100:
                print("You have reached the maximum of 100 questions. Finishing input now.")
                break
        elif nav == "b":
            # remove current question entry and go back one
            if questions:
                questions.pop()
            if questions:
                print("\nRevising the previous question (it will be re-entered)...")
                last = questions.pop()
                # push back so user re-enters (simple approach)
                continue
        elif nav == "d":
            if len(questions) >= 2:
                print("\n--- Manual input complete. ---\n")
                break
            else:
                print("You must have at least 2 questions. Continue adding more.")
        else:
            if len(questions) >= 100:
                print("You have reached the maximum of 100 questions. Finishing input now.")
                break

    if questions:
        print("Summary of your manually entered questions:\n")
        for qd in questions:
            typ = "CRITICAL" if qd["is_critical"] else "STANDARD"
            print(f"[Question {qd['id']}] {qd['text']}")
            for i, alt in enumerate(qd["alternatives"], 1):
                letter = chr(ord('A') + i - 1)
                print(f"  {letter}) {alt}")
            print(f"  Type: {typ}\n")
    else:
        print("No questions were entered.\n")

    return questions


def _prompt_correct_answers_for_question(alternatives: list[str]) -> list[str]:
    if not alternatives:
        return []
    print("\nMark the correct answer(s) for this question.")
    print("Enter letters or numbers separated by commas (e.g., A,C or 1,3).")
    print("Press ENTER to mark ALL alternatives as correct.")
    print("Tip: You can also type 'all'.")
    legend = ", ".join(f"{chr(ord('A')+i)}={i+1}" for i in range(len(alternatives)))
    print("Legend:", legend)
    while True:
        raw = input("Correct selection(s): ").strip()
        if raw == "" or raw.lower() == "all":
            return alternatives[:]
        tokens = [t.strip() for chunk in raw.replace(",", " ").split() for t in [chunk] if t.strip()]
        if not tokens:
            print("Please enter something, or press ENTER for ALL.")
            continue
        picks = set()
        ok = True
        for t in tokens:
            if len(t) == 1 and t.isalpha():
                idx = (ord(t.upper()) - ord('A')) + 1
            else:
                try:
                    idx = int(t)
                except ValueError:
                    print(f"Unrecognized token '{t}'.")
                    ok = False
                    break
            if not (1 <= idx <= len(alternatives)):
                print(f"Out of range: '{t}'.")
                ok = False
                break
            picks.add(idx)
        if not ok or not picks:
            continue
        return [alternatives[i-1] for i in sorted(picks)]


def prompt_save_decision():
    while True:
        print("\nWould you like to save your questions?")
        print("Press j  – Save as both JSON and text file")
        print("Press c  – Continue without saving")
        c = input("Choice: ").strip().lower()
        if c in ("j", "c"):
            return c
        print("Invalid choice.")


# -------------- DECoys + recovery kit (passwordless; AAD; AUTH-CATALOG) --------------

def _prompt_decoy_secrets() -> list[str]:
    """
    Ask for up to 5 decoy secrets (plaintexts). Empty input stops early.
    """
    decoys = []
    print("\n--- Optional: Configure up to FIVE decoy secrets ---")
    print("A decoy is returned when real restoration criteria are not met.")
    print("They should look fully plausible. The text you enter here is what will be revealed.")
    print("(Press ENTER on a blank line to stop adding decoys.)\n")
    for i in range(1, 6):
        s = input(f"Enter decoy secret #{i} (leave blank to stop): ")
        if not s:
            break
        decoys.append(s)
    if not decoys:
        # Always have at least one decoy so the system never fails closed
        default_msg = "System: Recovery completed successfully."
        print(f"\n(No decoys provided. Adding a default decoy: \"{default_msg}\")")
        decoys.append(default_msg)
    return decoys


def save_questions(questions):
    """
    Builds and saves a SELF-CONTAINED recovery kit (passwordless per-answer keys).
    Enforces a minimum combinatorial hardness before allowing kit generation.

    NEW: Generates *one real* secret and up to *five decoy* secrets. The JSON contains
    per-answer encrypted shares for: real only on correct alternatives (others carry
    indistinguishable random bytes), while each decoy has shares assigned for *all*
    alternatives to guarantee a successful reconstruction path.
    """
    print("\n--- Cryptographic Parameter Setup ---")
    real_secret = get_nonempty_secret("Enter the secret to be protected: ")
    real_bytes = real_secret.encode("utf-8")
    real_b64 = base64.b64encode(real_bytes).decode()

    # Optional decoys
    decoy_texts = _prompt_decoy_secrets()
    decoy_bytes_list = [d.encode("utf-8") for d in decoy_texts]
    decoy_b64_list = [base64.b64encode(b).decode() for b in decoy_bytes_list]

    total_correct = sum(len(q.get("correct_answers", [])) for q in questions)
    total_alts = sum(len(q.get("alternatives", [])) for q in questions)
    total_incorrect = max(0, total_alts - total_correct)
    log_debug("Counts computed for kit build.",
              level="INFO",
              component="CRYPTO",
              details={"total_correct": total_correct, "total_alternatives": total_alts, "total_incorrect": total_incorrect})

    if total_correct == 0:
        print("ERROR: No correct answers were defined across your questions. At least one is required.")
        return

    # threshold bounds based on real shares available (policy)
    min_thr = _policy_min_threshold(total_correct)
    max_thr = total_correct
    print(f"\n[Policy] Minimum threshold for your {total_correct} real share(s) is {min_thr}.")
    r_thr = get_threshold("Enter the real threshold", min_thr, max_thr)

    # Pad size must accommodate the longest base64 across real+decoys
    max_b64_len = max(len(real_b64), *(len(db64) for db64 in decoy_b64_list))
    pad_size = prompt_pad_size_multi(max_b64_len)

    # Argon2 parameters
    arg_time, arg_mem, arg_par = prompt_argon2_parameters()
    log_debug("Argon2id parameters confirmed for kit.",
              level="INFO",
              component="CRYPTO",
              details={"time_cost": arg_time, "memory_cost": arg_mem, "parallelism": arg_par})

    # --- Combinatorial hardness gate (for the REAL path) ---
    bits = _combinatorial_bits(total_alts, total_correct, r_thr)
    if not math.isfinite(bits) or bits < SECQ_MIN_BITS:
        print(f"\n[ABORT] Combinatorial hardness too low: ~{bits:.1f} bits "
              f"for N={total_alts}, C={total_correct}, T={r_thr}.")
        print("Add more questions/alternatives and/or increase the threshold, then try again.\n")
        return
    else:
        print(f"[OK] Combinatorial hardness: ~{bits:.1f} bits.")

    # ---------- Build global alternative index ----------
    # Order: [(q_hash, a_hash, q_text, alt_text, is_correct)]
    all_items: list[tuple[str, str, str, str, bool]] = []
    for q in questions:
        q_text = q["text"]
        alts = q["alternatives"]
        q_hash = _integrity_hash_for_kit(q_text, alts)
        correct_set_norm = set(_norm_for_kit(a) for a in q.get("correct_answers", []))
        for alt in alts:
            is_correct = _norm_for_kit(alt) in correct_set_norm
            all_items.append((q_hash, _alt_hash_for_kit(alt), q_text, alt, is_correct))
    total_alts = len(all_items)

    # ---------- Generate shares ----------
    # REAL: shares only for the number of correct alternatives
    try:
        real_shares_correct = asyncio.run(
            sss_split(real_b64.encode("utf-8"), sum(1 for it in all_items if it[4]), r_thr, pad=pad_size)
        )
    except Exception as e:
        log_exception(e, "Error splitting REAL secret")
        return

    # DECOYS: produce for ALL alternatives; threshold choices:
    #   - First decoy uses threshold=1 (guarantees return value even with very few picks)
    #   - Remaining decoys use threshold=r_thr (indistinguishable thresholds externally)
    decoy_thresholds = [1] + [r_thr] * (len(decoy_b64_list) - 1)
    decoy_shares_by_idx: list[list[bytearray]] = []
    try:
        for db64, thr in zip(decoy_b64_list, decoy_thresholds):
            shares = asyncio.run(sss_split(db64.encode("utf-8"), total_alts, thr, pad=pad_size))
            decoy_shares_by_idx.append(shares)
    except Exception as e:
        log_exception(e, "Error splitting DECOY secret(s)")
        return

    # ---------- AUTH CATALOG (indistinguishable) ----------
    # For each secret (real + decoys), store (salt, HMAC(secret)) but do not reveal which is which.
    def _auth_entry(secret_bytes: bytes) -> dict:
        salt = os.urandom(16)
        kdf = HKDF(algorithm=hashes.SHA256(), length=32, salt=salt, info=b"SECQ final-auth v3")
        k_auth = kdf.derive(secret_bytes)
        tag = hmac.new(k_auth, secret_bytes, digestmod="sha256").digest()
        return {"salt": base64.b64encode(salt).decode(), "hmac_sha256": base64.b64encode(tag).decode()}

    auth_catalog = [_auth_entry(real_bytes)] + [_auth_entry(b) for b in decoy_bytes_list]
    # Shuffle for stronger indistinguishability (store randomized order)
    secrets_perm = list(range(len(auth_catalog)))
    secrets.shuffle(secrets_perm)
    auth_catalog = [auth_catalog[i] for i in secrets_perm]

    # ---------- Encrypt per-answer shares for each secret variant ----------
    # For the REAL secret (index 0): only correct alternatives carry valid real shares.
    # For incorrect alternatives we store indistinguishable random bytes of share_len.
    encrypted_shares: dict[str, dict[str, dict]] = {}
    real_idx = 0
    share_len = pad_size + 1  # sss-bridge share size (pad bytes + 1 byte x-coordinate)

    def _enc_one_share(plaintext_share: bytes, q_hash: str, alt_text: str, alg_choice: str) -> dict:
        salt = os.urandom(16)
        key = _derive_answer_key(alt_text, salt, arg_time, arg_mem, arg_par)
        aad = _aad_bytes(q_hash, _alt_hash_for_kit(alt_text), alg_choice)
        if alg_choice == "chacha20poly1305":
            enc = encrypt_chacha20poly1305(plaintext_share, key, aad=aad)
            return {
                "ciphertext": enc["ciphertext"],
                "nonce": enc["nonce"],
                "algorithm": "chacha20poly1305",
                "salt": base64.b64encode(salt).decode(),
                "kdf": {"type": "argon2id", "t": arg_time, "m": arg_mem, "p": arg_par, "len": 32}
            }
        else:
            enc = encrypt_aes256gcm(plaintext_share, key, aad=aad)
            return {
                "ciphertext": enc["ciphertext"],
                "nonce": enc["nonce"],
                "tag": enc["tag"],
                "algorithm": "aes256gcm",
                "salt": base64.b64encode(salt).decode(),
                "kdf": {"type": "argon2id", "t": arg_time, "m": arg_mem, "p": arg_par, "len": 32}
            }

    # Walk all alternatives in global order so decoy shares map 1:1 by index
    for global_idx, (q_hash, a_hash, q_text, alt_text, is_corr) in enumerate(all_items):
        encrypted_shares.setdefault(q_hash, {})
        per_alt_block = {}
        # s0 => REAL path
        if is_corr:
            if real_idx >= len(real_shares_correct):
                log_error("Internal error: real_idx overflow", None, {"real_idx": real_idx, "len": len(real_shares_correct)})
                real_share = os.urandom(share_len)  # fallback indistinguishable
            else:
                real_share = bytes(real_shares_correct[real_idx])
                real_idx += 1
        else:
            real_share = os.urandom(share_len)  # indistinguishable filler for incorrect alts
        per_alt_block["s0"] = _enc_one_share(real_share, q_hash, alt_text, secrets.choice(["chacha20poly1305", "aes256gcm"]))

        # s1..sN => decoys (always valid shares for all alts)
        for decoy_i, shares_list in enumerate(decoy_shares_by_idx, start=1):
            dec_share = bytes(shares_list[global_idx])
            per_alt_block[f"s{decoy_i}"] = _enc_one_share(dec_share, q_hash, alt_text, secrets.choice(["chacha20poly1305", "aes256gcm"]))

        encrypted_shares[q_hash][a_hash] = per_alt_block

        log_debug(
            "Mapped Q/A to encrypted multi-secret shares.",
            level="INFO",
            component="CRYPTO",
            details={
                "q_text": q_text,
                "alt_text": alt_text,
                "q_hash": q_hash,
                "alt_hash": a_hash,
                "real_valid": bool(is_corr),
                "decoy_variants": len(decoy_shares_by_idx)
            }
        )

    questions_out = []
    for q in questions:
        questions_out.append({
            "id": q["id"],
            "text": q["text"],
            "alternatives": q["alternatives"],
            "is_critical": bool(q.get("is_critical", False)),
            "integrity_hash": _integrity_hash_for_kit(q["text"], q["alternatives"])
        })

    recovery_kit = {
        "config": {
            "real_threshold": r_thr,
            "pad_size": pad_size,
            "argon2_params": {"time_cost": arg_time, "memory_cost": arg_mem, "parallelism": arg_par},
            "version": KIT_VERSION,
            "secrets_count": 1 + len(decoy_b64_list),
            "auth_catalog": auth_catalog  # randomized order; indistinguishable
        },
        "questions": questions_out,
        "encrypted_shares": encrypted_shares
    }

    # persist files
    SAVE_DIR.mkdir(parents=True, exist_ok=True)
    base_name = "user_config"
    json_file = get_next_filename(SAVE_DIR, base_name, "json")
    txt_file = get_next_filename(SAVE_DIR, base_name, "txt")

    with open(json_file, "w", encoding="utf-8") as jf:
        json.dump(recovery_kit, jf, indent=2)

    with open(txt_file, "w", encoding="utf-8") as tf:
        tf.write("--- CRYPTOGRAPHIC CONFIGURATION ---\n")
        tf.write("Secret: [encrypted via SSS; not stored in JSON]\n")
        tf.write(f"Shamir Threshold (real path): {r_thr}\n")
        tf.write(f"Pad Size: {pad_size}\n")
        tf.write("Argon2id Parameters:\n")
        tf.write(f"  - Time Cost: {arg_time}\n")
        tf.write(f"  - Memory Cost: {arg_mem} KiB\n")
        tf.write(f"  - Parallelism: {arg_par}\n")
        tf.write(f"\nAuth Catalog Entries (real+decoys, shuffled): {len(auth_catalog)}\n")
        tf.write("\n--- SECURITY QUESTIONS ---\n\n")
        for q in questions:
            qtype = "CRITICAL" if q.get("is_critical") else "STANDARD"
            tf.write(f"[Question {q['id']}] {q['text']} (Type: {qtype})\n\n")
            for i, alt in enumerate(q['alternatives'], 1):
                letter = chr(ord('A') + i - 1)
                tf.write(f"{letter}) {alt}\n")
            tf.write("\n---\n\n")

    print(f"Saved configuration to '{json_file}' and '{txt_file}'.")
    log_debug("Recovery kit saved (passwordless; with auth catalog; decoy-enabled).", level="INFO")


# ---------- Recovery UI Flow from a saved kit (real + decoys, indistinguishable) ----------

def _try_combine_with_sampling(partials: list[bytes], r_thr: int) -> bytes | None:
    """
    Try to combine using multiple T-subsets:
      - Exhaustive if small (<= 5000 combinations)
      - Otherwise sample up to 200 random unique T-subsets
    Returns combined bytes on success, or None.
    """
    n = len(partials)
    if n < r_thr:
        return None
    if n == r_thr:
        try:
            return asyncio.run(sss_combine(partials))
        except Exception:
            return None

    max_exhaustive = 5000
    total_combos = math.comb(n, r_thr) if hasattr(math, "comb") else float("inf")

    # Exhaustive if small
    if total_combos <= max_exhaustive:
        for idxs in combinations(range(n), r_thr):
            try:
                return asyncio.run(sss_combine([partials[i] for i in idxs]))
            except Exception:
                continue
        return None

    # Random sampling (cryptographically random selection of indices)
    def sample_indices(nv: int, kv: int) -> tuple[int, ...]:
        s = set()
        while len(s) < kv:
            s.add(secrets.randbelow(nv))
        return tuple(sorted(s))

    seen = set()
    for _ in range(200):
        idxs = sample_indices(n, r_thr)
        if idxs in seen:
            continue
        seen.add(idxs)
        try:
            return asyncio.run(sss_combine([partials[i] for i in idxs]))
        except Exception:
            continue
    return None


def run_recovery_kit_flow(kit: dict, kit_path: Path):
    """
    Use the loaded recovery kit to reconstruct the secret:
      - Show config
      - Present questions via curses multi-select
      - Attempt REAL reconstruction from selected answers (needs >=T true shares)
      - If that fails, deterministically route to one DECOY and reconstruct from the same selections
      - Verify against AUTH CATALOG without revealing which secret matched
      - Print plausibly identical success output for real/decoy
    """
    try:
        cfg = kit.get("config") or {}
        questions = kit.get("questions") or []
        enc_shares = kit.get("encrypted_shares") or {}
        r_thr = int(cfg.get("real_threshold"))
        arg = cfg.get("argon2_params") or {}
        arg_time = int(arg.get("time_cost"))
        arg_mem = int(arg.get("memory_cost"))
        arg_par = int(arg.get("parallelism"))
        secrets_count = int(cfg.get("secrets_count", 1))
        auth_catalog = list(cfg.get("auth_catalog", []))
    except Exception as e:
        log_exception(e, "Invalid kit structure.")
        print("ERROR: Kit structure invalid or missing fields.")
        return

    # Summary
    print("\n--- LOADED RECOVERY KIT ---\n")
    print(f"File           : {kit_path.name}")
    print(f"Threshold (T)  : {r_thr}  [real path]")
    print(f"Pad Size       : {cfg.get('pad_size')}")
    print("Argon2id Params:")
    print(f"  - Time Cost  : {arg_time}")
    print(f"  - Memory Cost: {arg_mem} KiB")
    print(f"  - Parallelism: {arg_par}")
    print(f"Auth Catalog   : {len(auth_catalog)} entries\n")

    log_debug("Loaded recovery kit.",
              level="INFO",
              component="CRYPTO",
              details={
                  "kit_file": str(kit_path),
                  "threshold": r_thr,
                  "pad_size": cfg.get("pad_size"),
                  "argon2": {"time_cost": arg_time, "memory_cost": arg_mem, "parallelism": arg_par},
                  "q_count": len(questions),
                  "secrets_count": secrets_count
              })

    if not questions or not enc_shares:
        print("ERROR: Kit missing questions or encrypted_shares.")
        log_error("Kit missing essential arrays.", details={"has_questions": bool(questions), "has_enc_shares": bool(enc_shares)})
        return

    # Present questions via multi-select
    print("--- Answer the security questions ---\n")
    chosen = []
    for i, q in enumerate(questions, 1):
        text = q.get("text", "")
        alts = list(q.get("alternatives", []))
        picks = curses.wrapper(
            lambda st: arrow_select_no_toggle(
                st, i, text, alts, pre_selected=None
            )
        )
        chosen.append({"q": q, "picks": picks})
        log_debug("Recovery UI picks for question.",
                  level="INFO",
                  component="GENERAL",
                  details={"q_id": q.get("id"), "q_text": text, "picked": picks})

    # --- Decrypt selected shares for s0 (REAL path attempt) ---
    partials_s0: list[bytes] = []
    selected_pairs: list[tuple[str, str, str, str]] = []  # (q_hash, a_hash, q_text, alt_text)
    for item in chosen:
        qobj = item["q"]
        picks = item["picks"]
        q_text = qobj.get("text", "")
        alts = qobj.get("alternatives", [])
        q_hash = qobj.get("integrity_hash") or _integrity_hash_for_kit(q_text, alts)
        q_block = enc_shares.get(q_hash)
        if not q_block:
            log_error("Missing encrypted_shares block for question hash.", details={"q_hash": q_hash})
            continue
        for alt in picks:
            alt_hash = _alt_hash_for_kit(alt)
            sblock = q_block.get(alt_hash) or {}
            entry = sblock.get("s0")
            if not entry:
                log_error("No encrypted entry for selected alternative (s0).", details={"q_hash": q_hash, "alt_hash": alt_hash, "alt_text": alt})
                continue
            selected_pairs.append((q_hash, alt_hash, q_text, alt))
            share_bytes = _decrypt_share_from_entry(entry, arg_time, arg_mem, arg_par,
                                                    q_hash=q_hash, alt_hash=alt_hash,
                                                    qid=qobj.get("id"), qtext=q_text, alt_text=alt)
            if share_bytes is not None:
                partials_s0.append(share_bytes)

    # Try REAL combine with threshold r_thr
    combined_bytes = _try_combine_with_sampling(partials_s0, r_thr)
    selected_catalog_index = None
    secret_variant_used = "UNKNOWN"

    if combined_bytes is None:
        # Route to a deterministic DECOY based on the selection
        idx = _decoy_pick_index([(qh, ah) for (qh, ah, _, _) in selected_pairs], max(0, secrets_count - 1))
        decoy_index = max(1, idx)  # ensure >=1 if any decoys exist
        # Decrypt decoy shares (same selected answers), attempt combine with flexible T from 1..min(k, r_thr)
        qhash_ahash_pairs = selected_pairs
        decoy_partials: list[bytes] = []
        for (q_hash, a_hash, q_text, alt_text) in qhash_ahash_pairs:
            block = enc_shares.get(q_hash, {}).get(a_hash, {})
            entry = block.get(f"s{decoy_index}")
            if not entry:
                continue
            sb = _decrypt_share_from_entry(entry, arg_time, arg_mem, arg_par,
                                           q_hash=q_hash, alt_hash=a_hash,
                                           qid=None, qtext=q_text, alt_text=alt_text)
            if sb is not None:
                decoy_partials.append(sb)

        # escalate if not enough shares (pull deterministically from unpicked alts)
        if not decoy_partials:
            decoy_partials = []

        # If still not combinable, pull additional shares deterministically from remaining alts
        def _pull_more_for_decoy(target_count: int):
            if target_count <= len(decoy_partials):
                return
            for q in questions:
                q_text = q.get("text", "")
                alts = q.get("alternatives", [])
                q_hash = q.get("integrity_hash") or _integrity_hash_for_kit(q_text, alts)
                for alt_text in alts:
                    a_hash = _alt_hash_for_kit(alt_text)
                    if any((qh == q_hash and ah == a_hash) for (qh, ah, _, _) in qhash_ahash_pairs):
                        continue  # skip already selected
                    entry = enc_shares.get(q_hash, {}).get(a_hash, {}).get(f"s{decoy_index}")
                    if not entry:
                        continue
                    sb = _decrypt_share_from_entry(entry, arg_time, arg_mem, arg_par,
                                                   q_hash=q_hash, alt_hash=a_hash,
                                                   qid=None, qtext=q_text, alt_text=alt_text)
                    if sb is not None:
                        decoy_partials.append(sb)
                        if len(decoy_partials) >= target_count:
                            return

        # Try thresholds from 1..min(len(decoy_partials), r_thr) and pull more if needed
        success = False
        for t_try in range(1, max(1, min(len(decoy_partials), r_thr)) + 1):
            candidate = _try_combine_with_sampling(decoy_partials, t_try)
            if candidate is not None:
                combined_bytes = candidate
                success = True
                break

        if not success:
            # Ensure at least r_thr shares by pulling more
            _pull_more_for_decoy(r_thr)
            for t_try in range(1, max(1, min(len(decoy_partials), r_thr)) + 1):
                candidate = _try_combine_with_sampling(decoy_partials, t_try)
                if candidate is not None:
                    combined_bytes = candidate
                    success = True
                    break

        if not success:
            print("Recovery failed unexpectedly. Please re-run and pick different answers.")
            return

        secret_variant_used = f"DECOY_{decoy_index}"
    else:
        secret_variant_used = "REAL"

    # Decode final secret (base64 → utf-8) and verify against AUTH CATALOG (indistinguishable)
    try:
        recovered_b64 = combined_bytes.decode("utf-8")
        final_secret_text = base64.b64decode(recovered_b64).decode("utf-8")

        # AUTH-CATALOG verification (no disclosure of which entry matched)
        matched = False
        for entry in auth_catalog:
            try:
                salt = base64.b64decode(entry.get("salt", ""))
                expected = base64.b64decode(entry.get("hmac_sha256", ""))
                kdf = HKDF(algorithm=hashes.SHA256(), length=32, salt=salt, info=b"SECQ final-auth v3")
                k_auth = kdf.derive(final_secret_text.encode("utf-8"))
                calc = hmac.new(k_auth, final_secret_text.encode("utf-8"), digestmod="sha256").digest()
                if hmac.compare_digest(calc, expected):
                    matched = True
                    break
            except Exception:
                continue

        print("\n[AUTH OK]" if matched else "\n[AUTH WARNING] (non-catalog secret)\n")
        print("--- SECRET RECONSTRUCTED ---")
        print(final_secret_text)
        print("-----------------------------\n")
        log_debug("Final secret reconstructed.", level="INFO", component="CRYPTO",
                  details={"final_secret_len": len(final_secret_text), "variant": secret_variant_used})
    except Exception as e:
        log_exception(e, "Final base64/utf-8 decode failed.")
        print("\nShares combined, but final decode failed (invalid base64 or encoding).\n")

    append_recovery_guide()
    log_debug("Recovery Mode complete.", level="INFO")

    # End-of-flow options (per requirement)
    print("Press 1 – Enter setup phase")
    print("Press 2 – Proceed to example demonstration")


# ---------- existing demonstration / combine path (kept; AAD added; ChaCha tag removed) ----------

def get_next_filename(base_dir, base_name, extension):
    idx = 0
    while True:
        idx += 1
        candidate = base_dir / (f"{base_name}.{extension}" if idx == 1 else f"{base_name}{idx}.{extension}")
        if not candidate.exists():
            return candidate


def check_required_files():
    needed_in_src = ["CipherForge.py", "example_questions25.json"]
    missing = []
    for f in needed_in_src:
        if not (SRC_DIR / f).exists():
            missing.append(f)
    modules_path = SRC_DIR / "modules"
    needed_in_modules = [
        "debug_utils.py",
        "input_utils.py",
        "log_processor.py",
        "security_utils.py",
        "split_utils.py",
        "sss_bridge.py",
        "ui_utils.py"
    ]
    for f in needed_in_modules:
        if not (modules_path / f).exists():
            missing.append(f"modules/{f}")
    if missing:
        log_error("Missing required files", None, {"missing": missing})
        print("ERROR - Missing files:", missing)
        sys.exit(1)


def prompt_argon2_parameters():
    print("\n--- Argon2id Parameter Setup ---")
    print("Use (n) normal defaults, (a) auto-calibrate, or (e) custom edit? [n/a/e] ", end="")
    choice_ = input().strip().lower()
    if choice_ == 'a':
        t, m_kib, p, ms = calibrate_argon2()
        print(f"Auto-calibrated: time_cost={t}, memory_cost={m_kib} KiB, parallelism={p} (~{ms:.1f} ms/guess)")
        return (t, m_kib, p)
    if choice_ != 'e':
        # Stronger defaults: 3 iters, 256 MiB, p=1
        print("Using DEFAULT Argon2id parameters: time_cost=3, memory_cost=262144, parallelism=1")
        input("Press ENTER to continue with these defaults...")
        return (3, 262144, 1)
    else:
        print("Enter custom Argon2id parameters:")
        tc = get_valid_int("time_cost (1..10)? ", 1, 10)
        mc = get_valid_int("memory_cost (8192..1048576)? ", 8192, 1048576)
        pl = get_valid_int("parallelism (1..32)? ", 1, 32)
        print(f"Using CUSTOM Argon2id parameters: time_cost={tc}, memory_cost={mc}, parallelism={pl}")
        return (tc, mc, pl)


def calc_qna_search_space(chosen):
    total = 1
    for q in chosen:
        n_alts = len(q["alternatives"])
        ways = (1 << n_alts) - 1 if n_alts > 0 else 1
        total *= max(1, ways)
    return total


def convert_seconds_to_dhms(seconds):
    out = {"years":0,"months":0,"days":0,"hours":0,"minutes":0,"seconds":0.0}
    if seconds <= 0: return out
    year_sec   = 365.25*24*3600
    month_sec  = 30.4375*24*3600
    day_sec    = 24*3600
    hour_sec   = 3600
    minute_sec = 60
    out["years"]   = int(seconds // year_sec); seconds %= year_sec
    out["months"]  = int(seconds // month_sec); seconds %= month_sec
    out["days"]    = int(seconds // day_sec); seconds %= day_sec
    out["hours"]   = int(seconds // hour_sec); seconds %= hour_sec
    out["minutes"] = int(seconds // minute_sec); seconds %= minute_sec
    out["seconds"] = seconds
    return out


def print_estimated_bruteforce_times(chosen, arg_time, arg_mem, arg_par,
                                     total_correct_lower: int | None = None,
                                     r_thr: int | None = None,
                                     decoy_present: bool = True):
    """
    Enhanced brute-force estimator (beta):
    - Shows search space for all non-empty answer subsets (per your UI).
    - Shows *lower bound* trials for reaching the real threshold: C(C_total, T).
    - Shows minimal trials for a decoy: 1 if at least one decoy with threshold=1, else C(N_total, T).
    - Compares with Argon2id vs WITHOUT Argon2id.
    - Includes Grover (sqrt) estimates for both cases.
    """
    import math
    search_space = max(1, calc_qna_search_space(chosen))
    single_guess_ms = estimate_argon2_time_ms(arg_time, arg_mem, arg_par, samples=1)
    # Assume a tight lower bound for "no Argon2" primitive crypto guess
    single_guess_ms_no_argon = 0.005  # 5 microseconds per attempt (model)

    # Total attempts to brute-force "any subset"
    total_classical_ms = search_space * single_guess_ms
    total_quantum_ms   = math.sqrt(search_space) * single_guess_ms
    total_classical_ms_na = search_space * single_guess_ms_no_argon
    total_quantum_ms_na   = math.sqrt(search_space) * single_guess_ms_no_argon

    # Real threshold lower-bound trials (choose exactly r_thr correct picks)
    trials_real_lb = None
    if total_correct_lower is not None and r_thr is not None and total_correct_lower >= r_thr:
        trials_real_lb = math.comb(total_correct_lower, r_thr)
    # Decoy minimal trials
    # We generated at least one decoy with threshold=1 when decoys are present.
    trials_decoy_min = 1 if decoy_present else None

    def _fmt_time(ms: float) -> dict:
        sec = ms / 1000.0
        return convert_seconds_to_dhms(sec)

    print("\n--- Estimated Brute-Force Difficulty ---")
    print(f"Total Q&A search space (non-empty subsets): {search_space:,.0f} guesses.")

    print("\n[WITH Argon2id] per-guess ~{:.3f} ms =>".format(single_guess_ms))
    cl = _fmt_time(total_classical_ms); qn = _fmt_time(total_quantum_ms)
    print(f"  Classical total time : {cl['years']}y {cl['months']}m {cl['days']}d {cl['hours']}h {cl['minutes']}m {cl['seconds']:.2f}s")
    print(f"  Quantum (Grover est.): {qn['years']}y {qn['months']}m {qn['days']}d {qn['hours']}h {qn['minutes']}m {qn['seconds']:.2f}s")

    print("\n[WITHOUT Argon2id] per-guess ~{:.3f} ms =>".format(single_guess_ms_no_argon))
    cl2 = _fmt_time(total_classical_ms_na); qn2 = _fmt_time(total_quantum_ms_na)
    print(f"  Classical total time : {cl2['years']}y {cl2['months']}m {cl2['days']}d {cl2['hours']}h {cl2['minutes']}m {cl2['seconds']:.2f}s")
    print(f"  Quantum (Grover est.): {qn2['years']}y {qn2['months']}m {qn2['days']}d {qn2['hours']}h {qn2['minutes']}m {qn2['seconds']:.2f}s")

    if trials_real_lb is not None:
        print(f"\nLower-bound trials to reach the REAL threshold: C(C_total={total_correct_lower}, T={r_thr}) = {trials_real_lb:,d}")
    if trials_decoy_min is not None:
        print(f"Minimal trials to reach *a decoy* (given at least one decoy has T=1): {trials_decoy_min}")

    print()  # newline


# ---------- Demo flow (unchanged UX; AAD added; ChaCha tag removed) ----------

def main():
    try:
        print("[INFO] Launching main.py...")
        log_debug("Starting demonstration flow (Option 2)...", level="INFO")

        if not QUESTIONS_PATH.exists():
            msg = f"Error: question file not found: {QUESTIONS_PATH}"
            log_error(msg)
            print(msg)
            return
        try:
            with open(QUESTIONS_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            empty_correct = 0
            for qd in data:
                if validate_question(qd):
                    qd["correct_answers"] = [
                        sanitize_input(normalize_text(ans)) for ans in qd.get("correct_answers", [])
                    ]
                    qd["alternatives"] = [
                        sanitize_input(normalize_text(alt)) for alt in qd["alternatives"]]
                    if not qd["correct_answers"]:
                        empty_correct += 1
                        qd["correct_answers"] = qd["alternatives"][:]
                        log_debug(
                            f"Question '{qd['text']}' had empty 'correct_answers'. Now set them all as correct.",
                            level="INFO"
                        )
            valid_data = [q for q in data if validate_question(q)]
            if empty_correct > 0:
                print(f"NOTICE: {empty_correct} question(s) had empty 'correct_answers'. "
                      f"All alternatives for those are treated as correct.\n")
        except Exception as e:
            log_exception(e, "Error loading question file")
            return
        if not valid_data:
            print("No valid questions found. Aborting.")
            return

        amt = get_valid_int(f"How many questions? (1..{len(valid_data)}): ", 1, len(valid_data))
        with chosen_lock:
            chosen = valid_data[:amt]

        # interactive selection with curses
        correct_cumulative = 0
        incorrect_cumulative = 0
        for i, qdict in enumerate(chosen, 1):
            picks, qtype = curses.wrapper(
                lambda s: arrow_select_clear_on_toggle(
                    s, i, qdict["text"], qdict["alternatives"],
                    pre_selected=qdict.get("user_answers"),
                    pre_qtype=1 if qdict.get("is_critical") else 0,
                    fixed_type=qdict.get("force_type")
                )
            )
            qdict["user_answers"] = picks
            qdict["is_critical"] = bool(qtype) if not qdict.get("force_type") \
                else (qdict["force_type"].upper() == "CRITICAL")

            c_local = 0
            i_local = 0
            cset_local = set(qdict.get("correct_answers", []))
            for alt_ in picks:
                if alt_ in cset_local:
                    c_local += 1
                else:
                    i_local += 1

            log_debug(
                f"Q{i}: text='{qdict['text']}' => user_picks={len(picks)} selected; local counts: correct={c_local}, incorrect={i_local}",
                level="DEBUG"
            )
            correct_cumulative += c_local
            incorrect_cumulative += i_local
            print(f"[FEEDBACK] After Q{i}: +{c_local} correct, +{i_local} incorrect.")
            print(f"Total so far => correct={correct_cumulative}, incorrect={incorrect_cumulative}\n")

        while True:
            done = editing_menu(chosen)
            if done:
                break

        correct_map = []
        incorrect_map = []
        for idx, q in enumerate(chosen, 1):
            cset = set(q.get("correct_answers", []))
            picks_ = q["user_answers"]
            local_c = 0
            local_i = 0
            for alt in picks_:
                if alt in cset:
                    correct_map.append((q, alt))
                    local_c += 1
                else:
                    incorrect_map.append((q, alt))
                    local_i += 1
            log_debug(f"After re-edit Q{idx}: c={local_c}, i={local_i}", level="INFO")

        c_count = len(correct_map)
        i_count = len(incorrect_map)
        log_debug(f"FINAL TALLY => c_count={c_count}, i_count={i_count}", level="INFO")
        print(f"\nOverall Tally => Correct picks={c_count}, Incorrect={i_count}.\n")

        # minimum correctness for demo path
        while True:
            if c_count < 10:
                if c_count == 0:
                    print("Zero correct picks => cannot proceed with Shamir’s Secret Sharing.")
                    print("(E => re-edit answers, N => abort)")
                    answer = input("Choice (E/N)? ").strip().upper()
                    if answer == 'E':
                        re_done = editing_menu(chosen)
                        if re_done:
                            correct_map.clear(); incorrect_map.clear()
                            for q_ in chosen:
                                cset_ = set(q_.get("correct_answers", []))
                                picks_ = q_["user_answers"]
                                for alt_ in picks_:
                                    (correct_map if alt_ in cset_ else incorrect_map).append((q_, alt_))
                            c_count = len(correct_map); i_count = len(incorrect_map)
                            print(f"\nNEW Tally => Correct picks={c_count}, Incorrect={i_count}.\n")
                            continue
                    elif answer == 'N':
                        confirm = input("Are you sure you want to abort? (y/n): ").strip().lower()
                        if confirm.startswith('y'):
                            print("Aborting.")
                            return
                        else:
                            continue
                    else:
                        print("Invalid choice.\n")
                        continue
                else:
                    print("Fewer than 10 correct => re-edit or abort.")
                    answer = input("Choice (E/N)? ").strip().upper()
                    if answer == 'E':
                        re_done = editing_menu(chosen)
                        if re_done:
                            correct_map.clear(); incorrect_map.clear()
                            for q_ in chosen:
                                cset_ = set(q_.get("correct_answers", []))
                                picks_ = q_["user_answers"]
                                for alt_ in picks_:
                                    (correct_map if alt_ in cset_ else incorrect_map).append((q_, alt_))
                            c_count = len(correct_map); i_count = len(incorrect_map)
                            print(f"\nNEW Tally => Correct picks={c_count}, Incorrect={i_count}.\n")
                            continue
                    elif answer == 'N':
                        confirm = input("Are you sure you want to abort? (y/n): ").strip().lower()
                        if confirm.startswith('y'):
                            print("Aborting.")
                            return
                        else:
                            continue
                    else:
                        print("Invalid choice.\n")
                        continue
            else:
                break

        prompt_text = "Real threshold"
        r_thr = get_threshold(prompt_text, 10, c_count)
        print(f"[INFO] Must pick >= {r_thr} correct picks to reconstruct real secret.\n")

        real_secret = get_nonempty_secret("Enter REAL secret: ")
        real_b64 = base64.b64encode(real_secret.encode()).decode()
        user_pad = prompt_pad_size_multi(len(real_b64))
        arg_time, arg_mem, arg_par = prompt_argon2_parameters()

        # Split real/dummy shares
        try:
            real_shares, dummy_shares = asyncio.run(
                split_secret_and_dummy(real_b64.encode(), c_count, i_count, r_thr, pad=user_pad)
            )
        except Exception as e:
            log_exception(e, "Error splitting secret")
            return

        def ephemeral_encrypt(data: bytes, q_text: str, alt_text: str, alg_choice: str) -> dict:
            """
            Demo-only: keep ephemeral credentials, but add AAD binding for AEAD.
            """
            ephemeral_pass = base64.b64encode(os.urandom(12)).decode()
            ephemeral_salt = os.urandom(16)
            ephemeral_key, ephemeral_salt_used = derive_or_recover_key(
                ephemeral_pass, ephemeral_salt, ephemeral=True,
                time_cost=arg_time, memory_cost=arg_mem, parallelism=arg_par
            )
            q_hash = _integrity_hash_for_kit(q_text, q["alternatives"])
            alt_hash = _alt_hash_for_kit(alt_text)
            aad = _aad_bytes(q_hash, alt_hash, alg_choice)

            if alg_choice == "chacha20poly1305":
                enc_obj = encrypt_chacha20poly1305(
                    data, ephemeral_key, aad=aad,
                    ephemeral_pass=ephemeral_pass,
                    ephemeral_salt=ephemeral_salt_used
                )
            else:
                enc_obj = encrypt_aes256gcm(
                    data, ephemeral_key, aad=aad,
                    ephemeral_pass=ephemeral_pass,
                    ephemeral_salt=ephemeral_salt_used
                )
            enc_obj["ephemeral_password"] = ephemeral_pass
            enc_obj["ephemeral_salt_b64"] = base64.b64encode(ephemeral_salt_used).decode()
            enc_obj["algorithm"] = alg_choice
            return enc_obj

        # Assign shares
        std_correct, crit_correct, std_incorrect, crit_incorrect = [], [], [], []
        for (q, alt) in correct_map:
            (crit_correct if q["is_critical"] else std_correct).append((q, alt))
        for (q, alt) in incorrect_map:
            (crit_incorrect if q["is_critical"] else std_incorrect).append((q, alt))

        share_idx_real = 0
        share_idx_dummy = 0

        for q_s, alt_s in std_correct:
            if share_idx_real >= len(real_shares): break
            sh = real_shares[share_idx_real]
            enc_full = ephemeral_encrypt(sh, q_s["text"], alt_s, secrets.choice(["chacha20poly1305","aes256gcm"]))
            q_s.setdefault("answer_shares", {})
            q_s["answer_shares"][alt_s] = {"enc_data": enc_full}
            for j in range(len(sh)): sh[j] = 0
            share_idx_real += 1

        for q_c, alt_c in crit_correct:
            if share_idx_real >= len(real_shares): break
            if not q_c.get("answer_shares", {}).get(alt_c):
                sh = real_shares[share_idx_real]
                enc_full = ephemeral_encrypt(sh, q_c["text"], alt_c, secrets.choice(["chacha20poly1305","aes256gcm"]))
                q_c.setdefault("answer_shares", {})
                q_c["answer_shares"][alt_c] = {"enc_data": enc_full}
                for j in range(len(sh)): sh[j] = 0
                share_idx_real += 1

        for q_s, alt_s in std_incorrect:
            if share_idx_dummy >= len(dummy_shares): break
            sh = dummy_shares[share_idx_dummy]
            enc_full = ephemeral_encrypt(sh, q_s["text"], alt_s, secrets.choice(["chacha20poly1305","aes256gcm"]))
            q_s.setdefault("answer_shares", {})
            q_s["answer_shares"][alt_s] = {"enc_data": enc_full}
            for j in range(len(sh)): sh[j] = 0
            share_idx_dummy += 1

        for q_c, alt_c in crit_incorrect:
            if share_idx_dummy >= len(dummy_shares): break
            if not q_c.get("answer_shares", {}).get(alt_c):
                sh = dummy_shares[share_idx_dummy]
                enc_full = ephemeral_encrypt(sh, q_c["text"], alt_c, secrets.choice(["chacha20poly1305","aes256gcm"]))
                q_c.setdefault("answer_shares", {})
                q_c["answer_shares"][alt_c] = {"enc_data": enc_full}
                for j in range(len(sh)): sh[j] = 0
                share_idx_dummy += 1

        print("\n--- Final Answering Phase ---\n")
        for i, q in enumerate(chosen, 1):
            picks2 = curses.wrapper(
                lambda st: arrow_select_no_toggle(
                    st, i, q["text"], q["alternatives"],
                    pre_selected=q.get("user_answers")
                )
            )
            q["user_answers"] = picks2

        while True:
            result = final_edit_menu(chosen)
            if result == 'G':
                log_debug("User finalize => combine secrets now.", level="INFO")
                break
            elif result == 'N':
                print("Aborted before final reconstruction. Exiting.")
                return

        # gather and decrypt selected shares (AAD bound)
        partials = []
        for q in chosen:
            if "user_answers" not in q or "answer_shares" not in q:
                continue
            q_hash = _integrity_hash_for_kit(q["text"], q["alternatives"])
            for alt in q["user_answers"]:
                share_info = q["answer_shares"].get(alt)
                if not share_info:
                    continue
                enc_data = share_info["enc_data"]
                ephemeral_pass = enc_data.get("ephemeral_password")
                ephemeral_salt_b64 = enc_data.get("ephemeral_salt_b64")
                if not ephemeral_pass or not ephemeral_salt_b64:
                    log_error("Missing ephemeral credentials for a selected answer.")
                    continue
                try:
                    ephemeral_salt = base64.b64decode(ephemeral_salt_b64)
                except Exception as e:
                    log_error(f"Base64 decode error for salt: {e}")
                    continue
                ephemeral_key, _ = derive_or_recover_key(
                    ephemeral_pass, ephemeral_salt, ephemeral=True,
                    time_cost=arg_time, memory_cost=arg_mem, parallelism=arg_par
                )
                dec_pt = None
                try:
                    alg = enc_data.get("algorithm")
                    aad = _aad_bytes(q_hash, _alt_hash_for_kit(alt), alg)
                    if alg == "chacha20poly1305":
                        dec_pt = decrypt_chacha20poly1305(enc_data, ephemeral_key, aad=aad)
                    else:
                        dec_pt = decrypt_aes256gcm(enc_data, ephemeral_key, aad=aad)
                    log_debug("Demo path decrypted share.",
                              level="INFO",
                              component="CRYPTO",
                              details={"share_sha3_256_hex": hash_share(dec_pt),
                                       "algorithm": alg})
                    partials.append(dec_pt)
                except Exception as e:
                    log_error("Decryption failed for a selected answer.", exc=e)

        if len(partials) < r_thr:
            print(f"\nNot enough shares to reconstruct. Got={len(partials)}, need={r_thr}")
            # Per requirement: offer options again at end of case
            print("Press 1 – Enter setup phase")
            print("Press 2 – Proceed to example demonstration")
            return
        try:
            combined_bytes = _try_combine_with_sampling(partials, r_thr)
            if combined_bytes is None:
                raise RuntimeError("No T-subset succeeded")
            reconstructed_real_b64 = combined_bytes.decode('utf-8')
            log_debug("Demo combine succeeded.", level="INFO", component="CRYPTO",
                      details={"combined_len": len(combined_bytes)})
        except Exception as e:
            log_exception(e, "SSS Combine failed during final reconstruction")
            reconstructed_real_b64 = None

        print("\n--- FINAL RECONSTRUCTION RESULTS ---\n")
        if reconstructed_real_b64:
            try:
                final_secret_text = base64.b64decode(reconstructed_real_b64).decode('utf-8')
                print(f"REAL SECRET recovered: {final_secret_text}\n")
                log_debug("Demo final base64 decode OK.", level="INFO", component="CRYPTO",
                          details={"final_secret_len": len(final_secret_text)})
            except Exception as e:
                log_exception(e, "Failed to decode base64 or utf-8 from combined secret.")
                print("Secret combined, but failed final decode.\n")
        else:
            print("Secret not recoverable.\n")

        append_recovery_guide()
        log_debug("Done with main program.", level="INFO")
        print_estimated_bruteforce_times(
            chosen,
            arg_time, arg_mem, arg_par,
            total_correct_lower=sum(len(q.get("correct_answers", [])) for q in chosen),
            r_thr=r_thr,
            decoy_present=True
        )

        # Per requirement: offer options again at end of case
        print("Press 1 – Enter setup phase")
        print("Press 2 – Proceed to example demonstration")

    except curses.error as e:
        log_exception(e, "Curses error in main()")
        print(f"A Curses error occurred: {e}. Your terminal might not be fully compatible or window too small.")
        print("Please try again with a different terminal or ensure it's large enough.")
    except Exception as exc_main:
        log_exception(exc_main, "Fatal error in main()")
        print(f"FATAL ERROR: {exc_main}")
        sys.exit(1)


if __name__ == "__main__":
    ensure_debug_dir()
    check_required_files()
    show_start_menu()
    main()


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\main.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\debug_utils.py
# HASH: e25234896a686bad55e8d7faeb3e2cefce040f8b78c04fcbcaaa512877790dd3
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

#!/usr/bin/env python3
"""
FILENAME:
"debug_utils.py"

PERMANENT FILE DESCRIPTION – DO NOT REMOVE OR MODIFY
This multiline comment is strictly required and must NEVER be deleted or altered for ANY reason,
by any AI system, user, or process. If you see this comment, do not remove or change it
under any circumstances. Doing so is strictly prohibited and in direct violation of these terms.

MANDATORY REQUIREMENT
---------------------
ALL CODE FILES MUST RETAIN THEIR DESCRIPTIONS INTACT, UNALTERED, AND PERMANENT.

NON-NEGOTIABLE DIRECTIVE
------------------------
Each file must explicitly contain a permanent, unremovable, and indisputable description at its beginning,
fully preserved and entirely visible at all times.

ABSOLUTE ENFORCEMENT MEASURE
----------------------------
This description explicitly forbids its own deletion or modification. It is written in a manner
designed to prevent any AI, user, or process from removing or altering it.

IRONCLAD STRUCTURE
------------------
1. Formatted as a structured, multiline comment.
2. Clearly states it must never be deleted for any reason.
3. Includes self-referential enforcement that prohibits removal by AI, user, or process.

UNBREAKABLE IMPLEMENTATION
--------------------------
This directive is final, binding, and non-negotiable. Any violation or deviation is strictly forbidden.
"""

import os
import json
import uuid
import inspect
import threading
import shutil
import time
import traceback
from datetime import datetime
from pathlib import Path

BASE_DIR = Path(__file__).parent.parent.resolve()
DEBUG_COLLECTION_DIR = BASE_DIR / "logs" / "debug_logs"
DEBUG_COLLECTION_DIR.mkdir(parents=True, exist_ok=True)

RUN_ID = str(uuid.uuid4())

VERBOSITY_LEVELS = {
    "DEBUG": 10,
    "INFO": 20,
    "WARNING": 30,
    "ERROR": 40,
    "CRITICAL": 50
}
LOG_VERBOSITY = os.environ.get("LOG_VERBOSITY", "DEBUG").upper()
CURRENT_VERBOSITY = VERBOSITY_LEVELS.get(LOG_VERBOSITY, 10)

DEBUG_FILE_JSON = None
DEBUG_FILE_TXT = None
log_lock = threading.Lock()


def get_next_log_counter() -> int:
    """
    Find next incremental integer for debug file naming.
    """
    counter = 1
    for file in DEBUG_COLLECTION_DIR.iterdir():
        if file.is_file() and file.name.startswith("debug_info") and file.name.endswith(".json"):
            try:
                cor = file.name.replace("debug_info", "").replace(".json", "")
                num_part = cor.split("_", maxsplit=1)[0]
                n = int(num_part)
                if n >= counter:
                    counter = n + 1
            except:
                pass
    return counter


def get_timestamp() -> str:
    return datetime.now().strftime("%Y-%m-%d_%H-%M-%S")


def archive_all_existing_logs():
    """
    Move all existing debug_info .json and .txt logs from debug_logs/ into debug_logs/archive/.
    """
    arch = DEBUG_COLLECTION_DIR / "archive"
    arch.mkdir(exist_ok=True)
    
    for f in DEBUG_COLLECTION_DIR.iterdir():
        if f.is_file() and f.name.startswith("debug_info") and f.suffix in [".json", ".txt"]:
            # Move everything into archive
            shutil.move(str(f), str(arch / f.name))


def ensure_debug_dir():
    """
    On each program start:
      1) Move all existing .json/.txt logs to `archive/`
      2) Create brand-new JSON/TXT debug log files for this run
    """
    global DEBUG_FILE_JSON, DEBUG_FILE_TXT

    # 1) Archive *all* existing logs so only new logs remain
    archive_all_existing_logs()

    # 2) Prepare brand-new log files for this run
    c = get_next_log_counter()
    ts = get_timestamp()
    DEBUG_FILE_JSON = DEBUG_COLLECTION_DIR / f"debug_info{c}_{ts}.json"
    DEBUG_FILE_TXT  = DEBUG_COLLECTION_DIR / f"debug_info{c}_{ts}.txt"

    # Write initial record
    start_entry = {
        "timestamp": datetime.now().isoformat(),
        "run_id": RUN_ID,
        "component": "SYSTEM",
        "level": "INFO",
        "message": "Start new run",
        "details": {"event": "Run Initialization"}
    }
    with log_lock:
        with open(DEBUG_FILE_JSON, "a", encoding="utf-8") as jf, open(DEBUG_FILE_TXT, "a", encoding="utf-8") as tf:
            jf.write(json.dumps(start_entry, indent=2) + "\n")
            tf.write(f"[{start_entry['timestamp']}] [INFO] [SYSTEM] Start new run (run_id={RUN_ID})\n")

    print(f"[DEBUG] Logging to JSON: {DEBUG_FILE_JSON}")
    print(f"[DEBUG] Logging to TXT : {DEBUG_FILE_TXT}")


def _write_log_json(entry: dict):
    with open(DEBUG_FILE_JSON, "a", encoding="utf-8") as jf:
        jf.write(json.dumps(entry, indent=2) + "\n")


def _write_log_txt(entry: dict):
    timestamp = entry.get("timestamp", "N/A")
    lvl = entry.get("level", "N/A")
    comp = entry.get("component", "N/A")
    caller = entry.get("caller", {})
    file_ = caller.get("file", "?")
    func_ = caller.get("function", "?")
    line_ = caller.get("line", "?")
    msg = entry.get("message", "")
    details = entry.get("details", {})
    ev = ""
    if "event" in details:
        ev = f" (event={details['event']})"
    line_txt = f"[{timestamp}] [{lvl}] [{comp}] {file_}:{func_}:{line_}{ev} - {msg}\n"

    with open(DEBUG_FILE_TXT, "a", encoding="utf-8") as tf:
        tf.write(line_txt)


def _do_log(level, component, msg, details=None):
    if details is None:
        details = {}
    nl = VERBOSITY_LEVELS.get(level.upper(), 10)
    if nl < CURRENT_VERBOSITY:
        return

    with log_lock:
        cf = inspect.currentframe().f_back
        entry = {
            "timestamp": datetime.now().isoformat(),
            "run_id": RUN_ID,
            "level": level.upper(),
            "component": component,
            "caller": {
                "file": os.path.basename(cf.f_code.co_filename),
                "function": cf.f_code.co_name,
                "line": cf.f_lineno
            },
            "message": msg,
            "details": details
        }
        _write_log_json(entry)
        _write_log_txt(entry)


def log_debug(msg: str, level="DEBUG", component="GENERAL", details=None):
    _do_log(level, component, msg, details)


def log_crypto_event(operation: str,
                     algorithm: str = None,
                     mode: str = None,
                     ephemeral_key: bytes = None,
                     argon_params: dict = None,
                     key_derived_bytes: bytes = None,
                     details: dict = None,
                     ephemeral: bool = False):
    if details is None:
        details = {}
    crypto_info = {
        "operation": operation,
        "algorithm": algorithm,
        "mode": mode,
        "ephemeral": ephemeral
    }
    if ephemeral_key is not None:
        import base64
        crypto_info["key_b64"] = base64.b64encode(ephemeral_key).decode()
    if key_derived_bytes is not None:
        import base64
        crypto_info["derived_key_b64"] = base64.b64encode(key_derived_bytes).decode()
    if argon_params:
        crypto_info["Argon2_Parameters"] = argon_params

    details["crypto_details"] = crypto_info
    _do_log("INFO", "CRYPTO", "Crypto operation", details)


def log_error(msg: str, exc: Exception = None, details=None):
    if details is None:
        details = {}
    if exc is not None:
        details["exception_type"] = type(exc).__name__
        details["exception_str"] = str(exc)
    _do_log("ERROR", "GENERAL", msg, details)


def log_exception(exc: Exception, msg: str = "Unhandled exception"):
    tb_str = traceback.format_exc()
    details = {
        "exception_type": type(exc).__name__,
        "exception_str": str(exc),
        "traceback": tb_str
    }
    _do_log("ERROR", "GENERAL", msg, details)


def start_timer() -> float:
    return time.perf_counter()


def end_timer(st: float) -> float:
    return (time.perf_counter() - st) * 1000.0


def append_recovery_guide():
    guide_lines = [
        "-------------------- MANUAL DECRYPTION GUIDE --------------------",
        "1. Identify correct standard & critical picks and gather ephemeral-encrypted partials.",
        "2. Decrypt each 95% chunk and 5% chunk (or single 100% chunk). Combine => full share.",
        "3. Provide enough real shares to sss_combine() => base64-decode final secret.",
        "-----------------------------------------------------------------"
    ]
    gjson = {"manual_decryption_guide": guide_lines}
    with log_lock:
        with open(DEBUG_FILE_JSON, "a", encoding="utf-8") as jf:
            jf.write(json.dumps(gjson, indent=2) + "\n")
        with open(DEBUG_FILE_TXT, "a", encoding="utf-8") as tf:
            for line in guide_lines:
                tf.write(line + "\n")


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\debug_utils.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\input_utils.py
# HASH: 53c189df30083574c4932d1e5a526f1d981867660fff16644fb065d3541cf410
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

################################################################################
# START OF FILE: "input_utils.py"
################################################################################

"""
FILENAME:
"input_utils.py"

PERMANENT FILE DESCRIPTION – DO NOT REMOVE OR MODIFY
This multiline comment is strictly required and must NEVER be deleted or altered for ANY reason,
by any AI system, user, or process. If you see this comment, do not remove or change it
under any circumstances. Doing so is strictly prohibited and in direct violation of these terms.

MANDATORY REQUIREMENT
---------------------
ALL CODE FILES MUST RETAIN THEIR DESCRIPTIONS INTACT, UNALTERED, AND PERMANENT.

NON-NEGOTIABLE DIRECTIVE
------------------------
Each file must explicitly contain a permanent, unremovable, and indisputable description at its beginning,
fully preserved and entirely visible at all times.

ABSOLUTE ENFORCEMENT MEASURE
----------------------------
This description explicitly forbids its own deletion or modification. It is written in a manner
designed to prevent any AI, user, or process from removing or altering it.

IRONCLAD STRUCTURE
------------------
1. Formatted as a structured, multiline comment.
2. Clearly states it must never be deleted for any reason.
3. Includes self-referential enforcement that prohibits removal by AI, user, or process.

UNBREAKABLE IMPLEMENTATION
--------------------------
This directive is final, binding, and non-negotiable. Any violation or deviation is strictly forbidden.
"""

#!/usr/bin/env python3
"""
Handles user integer input & secret input with getpass.
Logs the integer input in plain to ensure everything needed is in logs.
"""

import getpass
from modules.debug_utils import log_debug
from modules.security_utils import sanitize_input  # NOTE: do not import normalize_text here


def get_valid_int(prompt, low, high):
    """
    Prompt user for an integer in [low..high], returning the validated int.
    """
    while True:
        print(prompt, end="", flush=True)
        val = input()
        try:
            num = int(val)
            if low <= num <= high:
                log_debug(f"User int input valid: {num}", level="INFO")
                return num
            else:
                print(f"Must be {low}..{high}")
        except:
            print("Invalid integer input.")


def get_nonempty_secret(prompt):
    """
    Prompt user for a non-empty secret (via getpass).
    SECURITY FIX: Do NOT normalize high-entropy secrets (no NFKC).
    Accept bytes-as-UTF-8 string verbatim (strip NULs only). Enforce policy length.
    """
    POLICY_MAX = 256  # keep existing policy limit (no transformation)
    while True:
        s = getpass.getpass(prompt)
        # Remove NULs only; preserve everything else (no normalize_text)
        s = sanitize_input(s)
        if s.strip():
            if len(s) > POLICY_MAX:
                s = s[:POLICY_MAX]
            return s
        print("Cannot be empty.")
        log_debug("Empty secret => re-prompt", level="WARNING")

################################################################################
# END OF FILE: "input_utils.py"
################################################################################


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\input_utils.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\log_processor.py
# HASH: 9bfec2e43b9daa5f74853808a0789c0e891cba324b38df5b8b0be9538731ed1c
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

################################################################################
# START OF FILE: "log_processor.py"
################################################################################

"""
FILENAME:
"log_processor.py"

PERMANENT FILE DESCRIPTION – DO NOT REMOVE OR MODIFY
This multiline comment is strictly required and must NEVER be deleted or altered for ANY reason,
by any AI system, user, or process. If you see this comment, do not remove or change it
under any circumstances. Doing so is strictly prohibited and in direct violation of these terms.

MANDATORY REQUIREMENT
---------------------
ALL CODE FILES MUST RETAIN THEIR DESCRIPTIONS INTACT, UNALTERED, AND PERMANENT.

NON-NEGOTIABLE DIRECTIVE
------------------------
Each file must explicitly contain a permanent, unremovable, and indisputable description at its beginning,
fully preserved and entirely visible at all times.

ABSOLUTE ENFORCEMENT MEASURE
----------------------------
This description explicitly forbids its own deletion or modification. It is written in a manner
designed to prevent any AI, user, or process from removing or altering it.

IRONCLAD STRUCTURE
------------------
1. Formatted as a structured, multiline comment.
2. Clearly states it must never be deleted for any reason.
3. Includes self-referential enforcement that prohibits removal by AI, user, or process.

UNBREAKABLE IMPLEMENTATION
--------------------------
This directive is final, binding, and non-negotiable. Any violation or deviation is strictly forbidden.
"""

#!/usr/bin/env python3
"""
Tool to filter & display JSON logs from debug_logs.
Useful for forensic or debugging analysis.
"""

import argparse
import json
import sys
from pathlib import Path
from datetime import datetime

BASE_DIR = Path(__file__).parent.parent.resolve()
DEF_LOG_DIR = BASE_DIR / "logs" / "debug_logs"


def parse_args():
    ap = argparse.ArgumentParser("Forensic Log Processor")
    ap.add_argument("--log_dir", type=Path, default=DEF_LOG_DIR)
    ap.add_argument("--run_id", type=str)
    ap.add_argument("--component", type=str, help="e.g. CRYPTO, GENERAL, SYSTEM")
    ap.add_argument("--level", choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"])
    ap.add_argument("--start", type=str, help="Start time in ISO8601, e.g. 2025-03-08T17:00:00")
    ap.add_argument("--end", type=str, help="End time in ISO8601")
    ap.add_argument("--include_archive", action="store_true")
    ap.add_argument("--output", choices=["plain", "json"], default="plain")
    ap.add_argument("--crypto", action="store_true", help="Only show logs with component=CRYPTO")
    return ap.parse_args()


def load_log_file(fp: Path) -> list:
    entries = []
    try:
        with fp.open("r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    rec = json.loads(line)
                    entries.append(rec)
                except:
                    entries.append({"raw_line": line})
    except Exception as e:
        print(f"Failed reading {fp}: {e}", file=sys.stderr)
    return entries


def load_logs(log_dir: Path, include_archive: bool) -> list:
    main = list(log_dir.glob("debug_info*.json"))
    arch = []
    if include_archive:
        ardir = log_dir / "archive"
        if ardir.is_dir():
            arch = list(ardir.glob("debug_info*.json"))
    allf = main + arch
    out = []
    for ff in allf:
        out.extend(load_log_file(ff))
    return out


def filter_entries(entries: list,
                   run_id=None,
                   component=None,
                   level=None,
                   start=None,
                   end=None,
                   crypto_only=False):
    lvlmap = {"DEBUG": 10, "INFO": 20, "WARNING": 30, "ERROR": 40, "CRITICAL": 50}
    minlvl = lvlmap.get(level.upper(), 0) if level else 0
    start_dt = None
    if start:
        try:
            start_dt = datetime.fromisoformat(start)
        except:
            pass
    end_dt = None
    if end:
        try:
            end_dt = datetime.fromisoformat(end)
        except:
            pass

    ret = []
    for e in entries:
        if "timestamp" not in e:
            continue
        if run_id and e.get("run_id") != run_id:
            continue
        c = e.get("component", "")
        if crypto_only:
            if c != "CRYPTO":
                continue
        else:
            if component and c.lower() != component.lower():
                continue
        lv_str = e.get("level", "DEBUG").upper()
        lv_val = lvlmap.get(lv_str, 10)
        if lv_val < minlvl:
            continue
        try:
            dt = datetime.fromisoformat(e["timestamp"])
        except:
            continue
        if start_dt and dt < start_dt:
            continue
        if end_dt and dt > end_dt:
            continue
        ret.append(e)
    return ret


def print_plain(entries: list):
    """
    Print logs in a human-readable plain format.
    """
    for e in entries:
        ts = e.get("timestamp", "N/A")
        rid = e.get("run_id", "N/A")
        lvl = e.get("level", "N/A")
        comp = e.get("component", "N/A")
        c = e.get("caller", {})
        f = c.get("file", "?")
        fu = c.get("function", "?")
        ln = c.get("line", "?")
        msg = e.get("message", "")
        det = e.get("details", {})

        line = f"[{ts}] [{lvl}] [run_id={rid}] [{comp}] {f}:{fu}:{ln} - {msg}"
        print(line)

        if "crypto_details" in det:
            print("  CRYPTO DETAILS =>")
            crypto = det["crypto_details"]
            for k, v in crypto.items():
                print(f"    {k}: {v}")

        other_details = {k: v for k, v in det.items() if k != "crypto_details"}
        if other_details:
            import json
            print("  details=", json.dumps(other_details, indent=2))

        print()


def main():
    args = parse_args()
    if not args.log_dir.exists():
        print(f"Error: log_dir not exist: {args.log_dir}", file=sys.stderr)
        sys.exit(1)

    entries = load_logs(args.log_dir, args.include_archive)
    flt = filter_entries(
        entries,
        run_id=args.run_id,
        component=args.component,
        level=args.level,
        start=args.start,
        end=args.end,
        crypto_only=args.crypto
    )

    if args.output == "json":
        print(json.dumps(flt, indent=2))
    else:
        print_plain(flt)


if __name__ == "__main__":
    main()

################################################################################
# END OF FILE: "log_processor.py"
################################################################################


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\log_processor.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\security_utils.py
# HASH: f216d5f6b5429cb244da5f598bad2512ed38f119ab4e15d9134ccafd86d11408
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

################################################################################
# START OF FILE: "security_utils.py"
################################################################################

"""
FILENAME:
"security_utils.py"

PERMANENT FILE DESCRIPTION – DO NOT REMOVE OR MODIFY
This multiline comment is strictly required and must NEVER be deleted or altered for ANY reason,
by any AI system, user, or process. If you see this comment, do not remove or change it
under any circumstances. Doing so is strictly prohibited and in direct violation of these terms.

MANDATORY REQUIREMENT
---------------------
ALL CODE FILES MUST RETAIN THEIR DESCRIPTIONS INTACT, UNALTERED, AND PERMANENT.

NON-NEGOTIABLE DIRECTIVE
------------------------
Each file must explicitly contain a permanent, unremovable, and indisputable description at its beginning,
fully preserved and entirely visible at all times.

ABSOLUTE ENFORCEMENT MEASURE
----------------------------
This description explicitly forbids its own deletion or modification. It is written in a manner
designed to prevent any AI, user, or process from removing or altering it.

IRONCLAD STRUCTURE
------------------
1. Formatted as a structured, multiline comment.
2. Clearly states it must never be deleted for any reason.
3. Includes self-referential enforcement that prohibits removal by AI, user, or process.

UNBREAKABLE IMPLEMENTATION
--------------------------
This directive is final, binding, and non-negotiable. Any violation or deviation is strictly forbidden.
"""

#!/usr/bin/env python3
"""
Basic text normalization, share hashing with SHA3-256, etc.
Now includes question/answer hashing for Q&A sets.
"""

import unicodedata
import hashlib


def normalize_text(t: str) -> str:
    """
    Normalize text to NFKC, limiting length to 256 chars.
    """
    return unicodedata.normalize('NFKC', t)[:256]


def sanitize_input(t: str) -> str:
    """
    Remove null chars from the input.
    """
    return ''.join(ch for ch in t if ch not in "\0")


def validate_question(q) -> bool:
    """
    Check if a question dict has 'text', 'alternatives', 'correct_answers'.
    """
    if not isinstance(q, dict):
        return False
    if "text" not in q or "alternatives" not in q:
        return False
    if not isinstance(q["text"], str):
        return False
    if not isinstance(q["alternatives"], list):
        return False
    if "correct_answers" not in q:
        q["correct_answers"] = []
    return True


def hash_share(data: bytes) -> str:
    """
    SHA3-256 hash (hex) of a share's byte data.
    """
    return hashlib.sha3_256(data).hexdigest()


def verify_share_hash(data: bytes, expected: str) -> bool:
    """
    Verify the share's data matches the expected SHA3-256 hex digest.
    """
    return hashlib.sha3_256(data).hexdigest() == expected


def hash_question_and_answers(qdict: dict) -> str:
    """
    Create a stable SHA3-256 hash from:
    - question text
    - sorted alternatives
    - sorted correct_answers
    """
    text = qdict["text"]
    alt_list = sorted(qdict["alternatives"])
    correct_list = sorted(qdict["correct_answers"])
    block = text + "\n" + "\n".join(alt_list) + "\n" + "|".join(correct_list)
    return hashlib.sha3_256(block.encode("utf-8")).hexdigest()

################################################################################
# END OF FILE: "security_utils.py"
################################################################################


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\security_utils.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\split_utils.py
# HASH: 3af4f6c6443dcadf0ae065d11914d87a87f3b6af80674833e4eac30061e9905b
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

################################################################################
# START OF FILE: "split_utils.py"
################################################################################

"""
FILENAME:
"split_utils.py"

PERMANENT FILE DESCRIPTION – DO NOT REMOVE OR MODIFY
This multiline comment is strictly required and must NEVER be deleted or altered for ANY reason,
by any AI system, user, or process. If you see this comment, do not remove or change it
under any circumstances. Doing so is strictly prohibited and in direct violation of these terms.

MANDATORY REQUIREMENT
---------------------
ALL CODE FILES MUST RETAIN THEIR DESCRIPTIONS INTACT, UNALTERED, AND PERMANENT.

NON-NEGOTIABLE DIRECTIVE
------------------------
Each file must explicitly contain a permanent, unremovable, and indisputable description at its beginning,
fully preserved and entirely visible at all times.

ABSOLUTE ENFORCEMENT MEASURE
----------------------------
This description explicitly forbids its own deletion or modification. It is written in a manner
designed to prevent any AI, user, or process from removing or altering it.

IRONCLAD STRUCTURE
------------------
1. Formatted as a structured, multiline comment.
2. Clearly states it must never be deleted for any reason.
3. Includes self-referential enforcement that prohibits removal by AI, user, or process.

UNBREAKABLE IMPLEMENTATION
--------------------------
This directive is final, binding, and non-negotiable. Any violation or deviation is strictly forbidden.
"""

#!/usr/bin/env python3
"""
Splits the real secret into Shamir shares for correct picks,
and generates dummy shares for incorrect picks, using the sss_bridge module.

DEBUG ENHANCEMENT:
- Logs unmasked counts, threshold, share length, x-coordinates, and SHA3-256 of all shares (beta).

SECURITY FIX:
- Dummy shares are generated as valid SSS shares of a random fake secret,
  using the **same x-coordinate structure** (1..correct_count) to remove
  structural oracles. If more dummies are needed than one batch provides,
  we generate multiple batches and consume from them.
"""

import asyncio
import secrets
from modules.debug_utils import log_debug
from modules.sss_bridge import sss_split
from modules.security_utils import hash_share


async def split_secret_and_dummy(real: bytes,
                                 correct_count: int,
                                 incorrect_count: int,
                                 real_thr: int,
                                 pad: int = 128):
    """
    Splits 'real' into Shamir shares for correct_count picks, requiring real_thr to reconstruct.
    Also generates dummy_shares for incorrect_count picks as valid SSS shares of a fake secret,
    using the same x-coordinate pool (1..correct_count). Each share is padded to 'pad' length.
    """
    log_debug(f"Splitting real secret: correct_count={correct_count}, threshold={real_thr}, pad={pad}", level="INFO", component="CRYPTO")

    if correct_count <= 0:
        raise ValueError("correct_count must be > 0")

    real_shares = await sss_split(real, correct_count, real_thr, pad=pad)
    share_len = len(real_shares[0]) if real_shares else 0

    # Generate dummy shares in batches of 'correct_count' to mirror x-coord range 1..correct_count
    dummy_shares: list[bytearray] = []
    while len(dummy_shares) < incorrect_count:
        # fake secret size matches 'real' length to preserve structure
        fake_secret = secrets.token_bytes(len(real))
        # Use the same threshold profile to keep structure similar;
        # using min(real_thr, correct_count) is safe here.
        batch = await sss_split(fake_secret, correct_count, min(real_thr, correct_count), pad=pad)
        # consume as many as needed from this batch
        need = incorrect_count - len(dummy_shares)
        dummy_shares.extend(batch[:need])

    # Beta logging: unmasked hashes and x-coords for diagnosis
    try:
        xcoord_idx = share_len - 1 if share_len > 0 else 0
        real_xcoords = [int(s[xcoord_idx]) for s in real_shares] if real_shares else []
        dummy_xcoords = [int(s[xcoord_idx]) for s in dummy_shares] if dummy_shares else []
        real_hashes = [hash_share(bytes(s)) for s in real_shares]
        dummy_hashes = [hash_share(bytes(s)) for s in dummy_shares]
        log_debug(
            "SSS split summary (beta clear logging).",
            level="INFO",
            component="CRYPTO",
            details={
                "share_len": share_len,
                "pad": pad,
                "threshold": real_thr,
                "real_count": len(real_shares),
                "dummy_count": len(dummy_shares),
                "real_xcoords": real_xcoords,
                "dummy_xcoords": dummy_xcoords,
                "real_share_sha3_256": real_hashes,
                "dummy_share_sha3_256": dummy_hashes
            }
        )
    except Exception as e:
        log_debug(f"Non-fatal: failed to produce extended split logs: {e}", level="WARNING", component="CRYPTO")

    return real_shares, dummy_shares

################################################################################
# END OF FILE: "split_utils.py"
################################################################################


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\split_utils.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\sss_bridge.py
# HASH: 0dc3f698441bbddebda0d8c96ac289e8291348a7a7f164efc7eb58acf81cd483
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

#!/usr/bin/env python3
# sss_bridge.py — async adapter that keeps your 2-byte length + pad semantics
# and delegates Shamir math to the audited Node CLI.

from __future__ import annotations
import asyncio, json, base64
from pathlib import Path
from typing import List

from modules.debug_utils import log_debug  # existing logger
from modules.security_utils import hash_share  # your helper (unchanged)

# ----- helpers copied from your SSS.py (same behavior) -----
def pack_len(n: int) -> bytes:
    return n.to_bytes(2, "big")

def unpack_len(b: bytes) -> int:
    return int.from_bytes(b, "big")

# Compute filesystem locations relative to this file
SRC_DIR = Path(__file__).resolve().parents[1]      # ...\SECQ_CLI\SECQ_CLI\src
ROOT_DIR = SRC_DIR.parent                           # ...\SECQ_CLI\SECQ_CLI
BRIDGE_JS = ROOT_DIR / "bridge" / "sss-bridge.js"   # our Node CLI

def _assert_bridge_exists() -> None:
    if not BRIDGE_JS.exists():
        raise FileNotFoundError(
            f"Node bridge not found at '{BRIDGE_JS}'. "
            "Expected layout: <repo_root>\\bridge\\sss-bridge.js"
        )

async def _node_call(payload: dict, timeout: float = 15.0) -> dict:
    """Invoke Node CLI with JSON over stdin/out."""
    _assert_bridge_exists()
    proc = await asyncio.create_subprocess_exec(
        "node",
        str(BRIDGE_JS),
        stdin=asyncio.subprocess.PIPE,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )
    req = json.dumps(payload).encode("utf-8")
    out, err = await asyncio.wait_for(proc.communicate(input=req), timeout=timeout)

    # Node writes all responses on stdout; stderr indicates an unexpected failure.
    if err:
        try:
            log_debug(
                f"sss-bridge stderr: {err.decode(errors='ignore')}",
                level="WARNING",
                component="CRYPTO",
            )
        except Exception:
            pass

    try:
        resp = json.loads(out.decode("utf-8"))
    except Exception as e:
        raise RuntimeError(f"Invalid bridge response: {e}") from e

    if not resp.get("ok", False):
        raise RuntimeError(f"Bridge error: {resp.get('error','unknown')}")
    return resp

async def sss_split(secret: bytes, shares: int, threshold: int, pad: int = 128) -> List[bytearray]:
    """
    Preserve your semantics:
    - Prepend 2-byte big-endian length
    - Zero pad to 'pad' bytes
    - Call audited split; each share length = pad+1, last byte is x in [1..shares]
    """
    log_debug(
        "sss_split() via node-bridge",
        level="INFO",
        component="CRYPTO",
        details={"secret_len": len(secret), "shares": shares, "threshold": threshold, "pad": pad},
    )

    if shares < threshold:
        raise ValueError("shares < threshold in sss_split")
    if pad < len(secret):
        raise ValueError("pad must >= secret length")

    length_part = pack_len(len(secret))
    extra = pad - 2 - len(secret)
    if extra < 0:
        raise ValueError("pad too small unexpectedly")
    padded = length_part + secret + (b"\x00" * extra)

    resp = await _node_call(
        {
            "cmd": "split",
            "secret_b64": base64.b64encode(padded).decode(),
            "shares": shares,
            "threshold": threshold,
        }
    )

    out: List[bytearray] = []
    for b64 in resp["shares_b64"]:
        raw = base64.b64decode(b64)
        out.append(bytearray(raw))

    try:
        xcoords = [int(s[-1]) for s in out]
        sample_hashes = [hash_share(bytes(s)) for s in out[: min(3, len(out))]]
        log_debug(
            "sss_split() complete.",
            level="INFO",
            component="CRYPTO",
            details={"share_len": (pad + 1), "xcoords": xcoords, "sample_share_hashes": sample_hashes},
        )
    except Exception:
        # Logging should never break the crypto path
        pass

    return out

async def sss_combine(shares: List[bytes]) -> bytes:
    """
    Delegate combine to audited code; then strip 2-byte length and return real secret bytes.
    """
    log_debug(
        "sss_combine() via node-bridge",
        level="INFO",
        component="CRYPTO",
        details={"num_shares": len(shares), "share_len": (len(shares[0]) if shares else None)},
    )

    if not shares:
        raise ValueError("No shares passed to sss_combine")
    length = len(shares[0])
    if any(len(s) != length for s in shares):
        raise ValueError("Inconsistent share length")
    # x uniqueness & equal-length are rechecked by the audited library.

    resp = await _node_call(
        {
            "cmd": "combine",
            "shares_b64": [base64.b64encode(s).decode() for s in shares],
        }
    )

    padded = base64.b64decode(resp["secret_b64"])
    real_len = unpack_len(padded[:2])
    out_bytes = padded[2 : 2 + real_len] if real_len <= (len(padded) - 2) else bytes(padded)

    try:
        log_debug(
            "sss_combine() complete.",
            level="INFO",
            component="CRYPTO",
            details={"reconstructed_len": len(out_bytes), "reconstructed_sha3_256": hash_share(out_bytes)},
        )
    except Exception:
        pass

    return out_bytes


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\sss_bridge.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\ui_utils.py
# HASH: dfd18cb81e6f6a6c8672f2016a2986f30adcb1c8b04645e8db31d6176003a5b1
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

################################################################################
# START OF FILE: "ui_utils.py"
################################################################################

"""
FILENAME:
"ui_utils.py"

PERMANENT FILE DESCRIPTION – DO NOT REMOVE OR MODIFY
This multiline comment is strictly required and must NEVER be deleted or altered for ANY reason,
by any AI system, user, or process. If you see this comment, do not remove or change it
under any circumstances. Doing so is strictly prohibited and in direct violation of these terms.

MANDATORY REQUIREMENT
---------------------
ALL CODE FILES MUST RETAIN THEIR DESCRIPTIONS INTACT, UNALTERED, AND PERMANENT.

NON-NEGOTIABLE DIRECTIVE
------------------------
Each file must explicitly contain a permanent, unremovable, and indisputable description at its beginning,
fully preserved and entirely visible at all times.

ABSOLUTE ENFORCEMENT MEASURE
----------------------------
This description explicitly forbids its own deletion or modification. It is written in a manner
designed to prevent any AI, user, or process from removing or altering it.

IRONCLAD STRUCTURE
------------------
1. Formatted as a structured, multiline comment.
2. Clearly states it must never be deleted for any reason.
3. Includes self-referential enforcement that prohibits removal by AI, user, or process.

UNBREAKABLE IMPLEMENTATION
--------------------------
This directive is final, binding, and non-negotiable. Any violation or deviation is strictly forbidden.
"""

#!/usr/bin/env python3
"""
Implements arrow-based selection of answers & toggling question type,
plus editing menus to re-enter or single-edit.
"""

import curses
from modules.debug_utils import log_debug
from modules.security_utils import sanitize_input, normalize_text


def arrow_select_clear_on_toggle(stdscr, q_num, q_text, alts,
                                 pre_selected=None, pre_qtype=0, fixed_type=None):
    """
    Allows user to move with UP/DOWN, toggle selections with SPACE,
    optionally toggle question type (CRITICAL vs STANDARD) with 'T', unless fixed_type is set.
    If the user hits ENTER with no selection, show an error and wait.
    """
    curses.curs_set(0)
    q_text = sanitize_input(normalize_text(q_text))
    alts = [sanitize_input(normalize_text(a)) for a in alts]
    idx = 0
    chosen_mask = [False] * len(alts)
    toggle_allowed = (fixed_type is None)
    qtype = 1 if (fixed_type and fixed_type.upper() == "CRITICAL") else pre_qtype

    if pre_selected:
        for i, a in enumerate(alts):
            if a in pre_selected:
                chosen_mask[i] = True

    while True:
        stdscr.clear()
        stdscr.addstr(f"Q{q_num}. {q_text}\n\n")
        for i, alt in enumerate(alts):
            mark = "[X]" if chosen_mask[i] else "[ ]"
            arrow = "->" if i == idx else "  "
            stdscr.addstr(f"{arrow} {mark} {chr(65+i)}. {alt}\n")
        mode_str = "CRITICAL" if qtype == 1 else "STANDARD"
        if not toggle_allowed:
            mode_str += " (fixed)"
        stdscr.addstr(f"\nCurrent Type: {mode_str}\n")
        help_ = "UP/DOWN=move, SPACE=toggle"
        if toggle_allowed:
            help_ += ", T=switch type"
        help_ += ", ENTER=confirm.\n"
        stdscr.addstr(help_)

        key = stdscr.getch()
        if key == curses.KEY_UP and idx > 0:
            idx -= 1
        elif key == curses.KEY_DOWN and idx < len(alts) - 1:
            idx += 1
        elif key == ord(' '):
            chosen_mask[idx] = not chosen_mask[idx]
        elif toggle_allowed and key in [ord('t'), ord('T')]:
            # switching type resets selections
            chosen_mask = [False] * len(alts)
            qtype = 1 - qtype
        elif key == ord('\n'):
            if not any(chosen_mask):
                stdscr.addstr("\nError: Must select at least one.\n")
                stdscr.refresh()
                curses.napms(1500)
            else:
                break

    selected = [alts[i] for i, v in enumerate(chosen_mask) if v]
    mode_str = "CRITICAL" if qtype == 1 else "STANDARD"
    log_debug(f"Q{q_num} picks. Type={mode_str}", level="INFO")
    return selected, qtype


def arrow_select_no_toggle(stdscr, q_num, q_text, alts,
                           pre_selected=None):
    """
    Same arrow-based selection but no question-type toggle, for final phase.
    """
    curses.curs_set(0)
    q_text = sanitize_input(normalize_text(q_text))
    alts = [sanitize_input(normalize_text(a)) for a in alts]
    idx = 0
    chosen_mask = [False] * len(alts)
    if pre_selected:
        for i, a in enumerate(alts):
            if a in pre_selected:
                chosen_mask[i] = True

    while True:
        stdscr.clear()
        stdscr.addstr(f"Q{q_num}. {q_text}\n\n")
        for i, alt in enumerate(alts):
            mark = "[X]" if chosen_mask[i] else "[ ]"
            arrow = "->" if i == idx else "  "
            stdscr.addstr(f"{arrow} {mark} {chr(65+i)}. {alt}\n")
        stdscr.addstr("\nUP/DOWN=move, SPACE=toggle, ENTER=confirm.\n")

        key = stdscr.getch()
        if key == curses.KEY_UP and idx > 0:
            idx -= 1
        elif key == curses.KEY_DOWN and idx < len(alts) - 1:
            idx += 1
        elif key == ord(' '):
            chosen_mask[idx] = not chosen_mask[idx]
        elif key == ord('\n'):
            if not any(chosen_mask):
                stdscr.addstr("\nError: Must select at least one.\n")
                stdscr.refresh()
                curses.napms(1500)
            else:
                break

    selected = [alts[i] for i, v in enumerate(chosen_mask) if v]
    log_debug(f"Q{q_num} final picks", level="INFO")
    return selected


def editing_menu(chosen):
    """
    Command-based menu for re-entering or single-editing questions.
    """
    print("\n--- Editing Menu ---")
    print("Press 'E' to re-enter ALL answers.")
    print(f"Or type question #(1..{len(chosen)}) to edit a single. 'N' if done.\n")
    cmd = input("Choice: ").strip().upper()
    if cmd == 'N':
        return True
    if cmd == 'E':
        import curses
        for i, qdict in enumerate(chosen, 1):
            picks, qtype = curses.wrapper(
                lambda s: arrow_select_clear_on_toggle(
                    s, i, qdict["text"], qdict["alternatives"],
                    pre_selected=qdict.get("user_answers"),
                    pre_qtype=1 if qdict.get("is_critical") else 0,
                    fixed_type=qdict.get("force_type")
                )
            )
            qdict["user_answers"] = picks
            if qdict.get("force_type"):
                qdict["is_critical"] = (qdict["force_type"].upper() == "CRITICAL")
            else:
                qdict["is_critical"] = bool(qtype)
        return False
    try:
        num = int(cmd)
        if 1 <= num <= len(chosen):
            import curses
            qdict = chosen[num - 1]
            picks, qtype = curses.wrapper(
                lambda s: arrow_select_clear_on_toggle(
                    s, num, qdict["text"], qdict["alternatives"],
                    pre_selected=qdict.get("user_answers"),
                    pre_qtype=1 if qdict.get("is_critical") else 0,
                    fixed_type=qdict.get("force_type")
                )
            )
            qdict["user_answers"] = picks
            if qdict.get("force_type"):
                qdict["is_critical"] = (qdict["force_type"].upper() == "CRITICAL")
            else:
                qdict["is_critical"] = bool(qtype)
        else:
            print("Invalid question #.")
    except:
        print("Unrecognized cmd.")
    return False


def final_edit_menu(chosen):
    """
    Command-based menu for final pre-generation edits or abort.
    """
    print("\n--- Final Editing Menu ---")
    print("Press 'G' => generate secret. 'E' => re-enter ALL. or # => single. 'N'=>exit\n")
    cmd = input("Your choice: ").strip().upper()
    if cmd in ['G', 'N']:
        return cmd
    if cmd == 'E':
        import curses
        for i, qdict in enumerate(chosen, 1):
            picks, qtype = curses.wrapper(
                lambda s: arrow_select_clear_on_toggle(
                    s, i, qdict["text"], qdict["alternatives"],
                    pre_selected=qdict.get("user_answers"),
                    pre_qtype=1 if qdict.get("is_critical") else 0,
                    fixed_type=qdict.get("force_type")
                )
            )
            qdict["user_answers"] = picks
            if qdict.get("force_type"):
                qdict["is_critical"] = (qdict["force_type"].upper() == "CRITICAL")
            else:
                qdict["is_critical"] = bool(qtype)
        return None
    try:
        num = int(cmd)
        if 1 <= num <= len(chosen):
            import curses
            qdict = chosen[num - 1]
            picks, qtype = curses.wrapper(
                lambda s: arrow_select_clear_on_toggle(
                    s, num, qdict["text"], qdict["alternatives"],
                    pre_selected=qdict.get("user_answers"),
                    pre_qtype=1 if qdict.get("is_critical") else 0,
                    fixed_type=qdict.get("force_type")
                )
            )
            qdict["user_answers"] = picks
            if qdict.get("force_type"):
                qdict["is_critical"] = (qdict["force_type"].upper() == "CRITICAL")
            else:
                qdict["is_critical"] = bool(qtype)
        else:
            print("Invalid question #.")
    except:
        print("Unrecognized cmd.")
    return None

################################################################################
# END OF FILE: "ui_utils.py"
################################################################################


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\ui_utils.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\__init__.py
# HASH: 7428348539442d66470512193a75a784884655ad8a65b5c40ac2393a600ad68a
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

"""
FILENAME:
"__init__.py"

PERMANENT FILE DESCRIPTION – DO NOT REMOVE OR MODIFY
This multiline comment is strictly required and must NEVER be deleted or altered for ANY reason,
by any AI system, user, or process. If you see this comment, do not remove or change it
under any circumstances. Doing so is strictly prohibited and in direct violation of these terms.

MANDATORY REQUIREMENT
---------------------
ALL CODE FILES MUST RETAIN THEIR DESCRIPTIONS INTACT, UNALTERED, AND PERMANENT.

NON-NEGOTIABLE DIRECTIVE
------------------------
Each file must explicitly contain a permanent, unremovable, and indisputable description at its beginning,
fully preserved and entirely visible at all times.

ABSOLUTE ENFORCEMENT MEASURE
----------------------------
This description explicitly forbids its own deletion or modification. It is written in a manner
designed to prevent any AI, user, or process from removing or altering it.

IRONCLAD STRUCTURE
------------------
1. Formatted as a structured, multiline comment.
2. Clearly states it must never be deleted for any reason.
3. Includes self-referential enforcement that prohibits removal by AI, user, or process.

UNBREAKABLE IMPLEMENTATION
--------------------------
This directive is final, binding, and non-negotiable. Any violation or deviation is strictly forbidden.
"""

__all__ = [
    "debug_utils",
    "input_utils",
    "log_processor",
    "security_utils",
    "split_utils",
    "sss_bridge", # Use the new SSS bridge
    "ui_utils"
]


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\src\modules\__init__.py
########################################################################################################################


########################################################################################################################
# FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\bridge\sss-bridge.js
# HASH: 649e1c3b3a0854b5bca6a7925ccc6e1139a16e8a45e2b65f6312760b59c1cf0a
# TIMESTAMP: 2025-08-26_12-04-47
########################################################################################################################

#!/usr/bin/env node
// sss-bridge.js — JSON-over-stdin CLI around the audited library

const fs = require("fs");
const path = require("path");

// Load audited package from vendor folder, unchanged
const pkgPath = path.join(__dirname, "vendor", "shamir-secret-sharing-0.0.3");
const { split, combine } = require(pkgPath); // CommonJS default export (index.js)

const readStdin = () => fs.readFileSync(0, "utf8");
const ok = (obj) => process.stdout.write(JSON.stringify({ ok: true, ...obj }) + "\n");
const fail = (err) =>
  process.stdout.write(JSON.stringify({ ok: false, error: String(err && err.message ? err.message : err) }) + "\n");

(async () => {
  try {
    const req = JSON.parse(readStdin());

    if (req.cmd === "split") {
      if (typeof req.secret_b64 !== "string") throw new Error("secret_b64 missing");
      if (typeof req.shares !== "number" || typeof req.threshold !== "number") throw new Error("shares/threshold missing");
      const secret = new Uint8Array(Buffer.from(req.secret_b64, "base64"));
      const shares = await split(secret, req.shares, req.threshold);
      const shares_b64 = shares.map((u8) => Buffer.from(u8).toString("base64"));
      ok({ shares_b64 });
      return;
    }

    if (req.cmd === "combine") {
      if (!Array.isArray(req.shares_b64)) throw new Error("shares_b64 missing");
      const shares = req.shares_b64.map((b64) => new Uint8Array(Buffer.from(b64, "base64")));
      const secret = await combine(shares);
      ok({ secret_b64: Buffer.from(secret).toString("base64") });
      return;
    }

    throw new Error("unknown cmd");
  } catch (e) {
    fail(e);
  }
})();


########################################################################################################################
# END OF FILE: C:\Users\deskt\Desktop\Project_SECQ_CLI\SECQ_CLI\SECQ_CLI\bridge\sss-bridge.js
########################################################################################################################


========================================================================================================================
SUMMARY
Total Files: 11
Total Characters: 128307
Timestamp: 2025-08-26_12-04-47
========================================================================================================================
